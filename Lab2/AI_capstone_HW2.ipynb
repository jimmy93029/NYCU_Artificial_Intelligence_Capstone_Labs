{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimmy93029/NYCU_Artificial_Intelligence_Capstone_Labs/blob/main/Lab2/AI_capstone_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation\n"
      ],
      "metadata": {
        "id": "VvzKfb9lIhUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y swig\n",
        "!pip install box2d-py==2.3.5 --no-build-isolation"
      ],
      "metadata": {
        "id": "yRhpQdZKi_MS",
        "outputId": "18fcdde8-4504-4b62-d435-e3e764f840fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  swig4.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig4.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 30 not upgraded.\n",
            "Need to get 1,116 kB of archives.\n",
            "After this operation, 5,542 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
            "Fetched 1,116 kB in 0s (2,280 kB/s)\n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 126315 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting box2d-py==2.3.5\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp311-cp311-linux_x86_64.whl size=2351177 sha256=1feea477655f2b01a0aa01e7aaa755a98f441684611f7a64c7fa024b91416983\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/f1/0c/d56f4a2bdd12bae0a0693ec33f2f0daadb5eb9753c78fa5308\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"gymnasium[atari, accept-rom-license]\""
      ],
      "metadata": {
        "id": "YqiyOkX1mr8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1A6nWeoVDhwM"
      },
      "outputs": [],
      "source": [
        "!pip install stable-baselines3[extra] torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium[accept-rom-license,atari]"
      ],
      "metadata": {
        "id": "0fS5Mzipoh6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Shimmy"
      ],
      "metadata": {
        "id": "wDN3wimDp23W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzasS7KRwnec",
        "outputId": "1a9b3423-ba03-4ab9-86cc-a5e430ad0b00"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Base_dir = \"/content/drive/MyDrive/AI_capstone\""
      ],
      "metadata": {
        "id": "GoviRcxflWtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1 : Comparison on Atari\n",
        "\n",
        "```\n",
        "# Ê≠§ÂÖßÂÆπÊúÉÈ°ØÁ§∫ÁÇ∫Á®ãÂºèÁ¢º\n",
        "```\n",
        "\n",
        "67421"
      ],
      "metadata": {
        "id": "D-aX0ivnImtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ale_py\n",
        "# if using gymnasium\n",
        "import shimmy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import gymnasium as gym\n"
      ],
      "metadata": {
        "id": "tRPJ_totpsWg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as plt\n",
        "\n",
        "def plot_rewards(reward_dict):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for label, rewards in reward_dict.items():\n",
        "        plt.plot(rewards, label=label)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Total Reward\")\n",
        "    plt.title(\"Policy Comparison\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "sV2X5_picgvR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train"
      ],
      "metadata": {
        "id": "hzjgxeO6bqzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train REINFORCE"
      ],
      "metadata": {
        "id": "JWBLsisLb7Vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class CNNREINFORCEPolicy(nn.Module):\n",
        "    def __init__(self, act_dim):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 8, 4), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, 2), nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, 1), nn.ReLU()\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 22 * 16, 512), nn.ReLU(),\n",
        "            nn.Linear(512, act_dim),\n",
        "            nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, obs):\n",
        "        if isinstance(obs, np.ndarray):\n",
        "            obs = torch.tensor(obs, dtype=torch.float32)\n",
        "        obs = obs.permute(2, 0, 1).unsqueeze(0) / 255.0\n",
        "        return self.fc(self.conv(obs)).squeeze(0)\n",
        "\n",
        "\n",
        "class CNNValueNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 8, 4), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, 2), nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, 1), nn.ReLU()\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 22 * 16, 512), nn.ReLU(),\n",
        "            nn.Linear(512, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, obs):\n",
        "        if isinstance(obs, np.ndarray):\n",
        "            obs = torch.tensor(obs, dtype=torch.float32)\n",
        "        obs = obs.permute(2, 0, 1).unsqueeze(0) / 255.0\n",
        "        return self.fc(self.conv(obs)).squeeze()\n"
      ],
      "metadata": {
        "id": "IojLiequob2Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_reinforce_variant(env_id, variant=\"original\", num_episodes=500, lr=1e-4, gamma=0.99):\n",
        "    env = gym.make(env_id)\n",
        "    policy = CNNREINFORCEPolicy(env.action_space.n)\n",
        "    optimizer = optim.Adam(policy.parameters(), lr=lr)\n",
        "\n",
        "    if variant == \"advantage\":\n",
        "        value_net = CNNValueNet()\n",
        "        value_optimizer = optim.Adam(value_net.parameters(), lr=lr)\n",
        "\n",
        "    for ep in range(num_episodes):\n",
        "        obs, _ = env.reset()\n",
        "        log_probs, rewards, states = [], [], []\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            probs = policy(obs)\n",
        "            dist = torch.distributions.Categorical(probs)\n",
        "            action = dist.sample()\n",
        "            log_probs.append(dist.log_prob(action))\n",
        "            states.append(obs)\n",
        "            obs, reward, done, truncated, _ = env.step(action.item())\n",
        "            rewards.append(reward)\n",
        "\n",
        "        # Compute returns G_t\n",
        "        G = 0\n",
        "        returns = []\n",
        "        for r in reversed(rewards):\n",
        "            G = r + gamma * G\n",
        "            returns.insert(0, G)\n",
        "        returns = torch.tensor(returns, dtype=torch.float32)\n",
        "\n",
        "        # Compute loss\n",
        "        if variant == \"baseline\":\n",
        "            baseline = returns.mean()\n",
        "            advantages = returns - baseline\n",
        "        elif variant == \"advantage\":\n",
        "            values = torch.stack([value_net(s) for s in states])\n",
        "            advantages = returns - values.detach()\n",
        "\n",
        "            value_loss = nn.functional.mse_loss(values, returns)\n",
        "            value_optimizer.zero_grad()\n",
        "            value_loss.backward()\n",
        "            value_optimizer.step()\n",
        "        else:\n",
        "            advantages = returns\n",
        "\n",
        "        loss = -torch.sum(torch.stack(log_probs) * advantages)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f\"[{variant.upper()}] Ep {ep+1}/{num_episodes} | Reward: {sum(rewards):.1f}\")\n",
        "\n",
        "    env.close()\n",
        "    model_path = f\"/content/drive/MyDrive/AI_capstone/{env_id.split('/')[-1]}_{variant}_REINFORCE.pth\"\n",
        "    torch.save(policy.state_dict(), model_path)\n",
        "    print(f\"‚úÖ Saved model: {model_path}\")\n"
      ],
      "metadata": {
        "id": "KhXCV5zIbst9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test"
      ],
      "metadata": {
        "id": "KeyhRWP6I2du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "import os\n",
        "import gymnasium as gym\n",
        "\n",
        "def evaluate_reinforce(env_id, model_path, episodes=10, variant=\"original\"):\n",
        "    # Setup video directory in Google Drive\n",
        "    video_dir = f\"/content/drive/MyDrive/AI_capstone/videos/{env_id.replace('/', '_')}_{variant}\"\n",
        "    os.makedirs(video_dir, exist_ok=True)\n",
        "\n",
        "    # Load policy\n",
        "    act_dim = gym.make(env_id).action_space.n\n",
        "    policy = CNNREINFORCEPolicy(act_dim)\n",
        "    policy.load_state_dict(torch.load(model_path))\n",
        "    policy.eval()\n",
        "\n",
        "    # Wrap environment for video\n",
        "    env = RecordVideo(\n",
        "        gym.make(env_id, render_mode=\"rgb_array\"),\n",
        "        video_dir,\n",
        "        episode_trigger=lambda ep: ep == 0,\n",
        "        disable_logger=True\n",
        "    )\n",
        "\n",
        "    rewards = []\n",
        "    for ep in range(episodes):\n",
        "        obs, _ = env.reset()\n",
        "        done, total_reward, total_len = False, 0, 0\n",
        "\n",
        "        while not done:\n",
        "            with torch.no_grad():\n",
        "                obs_tensor = torch.tensor(obs, dtype=torch.float32)\n",
        "                probs = policy(obs_tensor)\n",
        "                action = torch.argmax(probs).item()\n",
        "            obs, reward, done, truncated, _ = env.step(action)\n",
        "            total_reward += reward\n",
        "            total_len += 1\n",
        "\n",
        "        rewards.append(total_reward)\n",
        "        print(f\"[EVAL] Episode {ep+1} | Reward: {total_reward:.2f} | Total len = {total_len}\")\n",
        "\n",
        "    env.close()\n",
        "    print(f\"üé• Video saved to: {video_dir}\")\n",
        "    return rewards\n"
      ],
      "metadata": {
        "id": "c215B5QvIp9r"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## main"
      ],
      "metadata": {
        "id": "8O3S5QznI-Uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "envs_discrete = [\"ALE/Assault-v5\"]\n",
        "# envs_continuous = [\"CarRacing-v2\", \"BipedalWalker-v3\"]\n",
        "\n",
        "# train_reinforce_variant(\"ALE/Assault-v5\", variant=\"original\", num_episodes=100)\n",
        "# train_reinforce_variant(\"ALE/Assault-v5\", variant=\"baseline\", num_episodes=100)\n",
        "train_reinforce_variant(\"ALE/Assault-v5\", variant=\"advantage\", num_episodes=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNpqFWwroljU",
        "outputId": "3e693cc7-a004-466d-871c-a924ddf7bc52"
      },
      "execution_count": 13,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ORIGINAL] Ep 1/100 | Reward: 126.0\n",
            "[ORIGINAL] Ep 2/100 | Reward: 273.0\n",
            "[ORIGINAL] Ep 3/100 | Reward: 126.0\n",
            "[ORIGINAL] Ep 4/100 | Reward: 168.0\n",
            "[ORIGINAL] Ep 5/100 | Reward: 357.0\n",
            "[ORIGINAL] Ep 6/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 7/100 | Reward: 231.0\n",
            "[ORIGINAL] Ep 8/100 | Reward: 378.0\n",
            "[ORIGINAL] Ep 9/100 | Reward: 147.0\n",
            "[ORIGINAL] Ep 10/100 | Reward: 252.0\n",
            "[ORIGINAL] Ep 11/100 | Reward: 210.0\n",
            "[ORIGINAL] Ep 12/100 | Reward: 210.0\n",
            "[ORIGINAL] Ep 13/100 | Reward: 399.0\n",
            "[ORIGINAL] Ep 14/100 | Reward: 231.0\n",
            "[ORIGINAL] Ep 15/100 | Reward: 273.0\n",
            "[ORIGINAL] Ep 16/100 | Reward: 252.0\n",
            "[ORIGINAL] Ep 17/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 18/100 | Reward: 378.0\n",
            "[ORIGINAL] Ep 19/100 | Reward: 273.0\n",
            "[ORIGINAL] Ep 20/100 | Reward: 252.0\n",
            "[ORIGINAL] Ep 21/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 22/100 | Reward: 336.0\n",
            "[ORIGINAL] Ep 23/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 24/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 25/100 | Reward: 210.0\n",
            "[ORIGINAL] Ep 26/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 27/100 | Reward: 168.0\n",
            "[ORIGINAL] Ep 28/100 | Reward: 273.0\n",
            "[ORIGINAL] Ep 29/100 | Reward: 273.0\n",
            "[ORIGINAL] Ep 30/100 | Reward: 315.0\n",
            "[ORIGINAL] Ep 31/100 | Reward: 168.0\n",
            "[ORIGINAL] Ep 32/100 | Reward: 252.0\n",
            "[ORIGINAL] Ep 33/100 | Reward: 210.0\n",
            "[ORIGINAL] Ep 34/100 | Reward: 231.0\n",
            "[ORIGINAL] Ep 35/100 | Reward: 231.0\n",
            "[ORIGINAL] Ep 36/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 37/100 | Reward: 231.0\n",
            "[ORIGINAL] Ep 38/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 39/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 40/100 | Reward: 294.0\n",
            "[ORIGINAL] Ep 41/100 | Reward: 252.0\n",
            "[ORIGINAL] Ep 42/100 | Reward: 231.0\n",
            "[ORIGINAL] Ep 43/100 | Reward: 210.0\n",
            "[ORIGINAL] Ep 44/100 | Reward: 84.0\n",
            "[ORIGINAL] Ep 45/100 | Reward: 273.0\n",
            "[ORIGINAL] Ep 46/100 | Reward: 210.0\n",
            "[ORIGINAL] Ep 47/100 | Reward: 231.0\n",
            "[ORIGINAL] Ep 48/100 | Reward: 294.0\n",
            "[ORIGINAL] Ep 49/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 50/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 51/100 | Reward: 210.0\n",
            "[ORIGINAL] Ep 52/100 | Reward: 210.0\n",
            "[ORIGINAL] Ep 53/100 | Reward: 273.0\n",
            "[ORIGINAL] Ep 54/100 | Reward: 483.0\n",
            "[ORIGINAL] Ep 55/100 | Reward: 210.0\n",
            "[ORIGINAL] Ep 56/100 | Reward: 252.0\n",
            "[ORIGINAL] Ep 57/100 | Reward: 294.0\n",
            "[ORIGINAL] Ep 58/100 | Reward: 273.0\n",
            "[ORIGINAL] Ep 59/100 | Reward: 168.0\n",
            "[ORIGINAL] Ep 60/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 61/100 | Reward: 147.0\n",
            "[ORIGINAL] Ep 62/100 | Reward: 252.0\n",
            "[ORIGINAL] Ep 63/100 | Reward: 336.0\n",
            "[ORIGINAL] Ep 64/100 | Reward: 252.0\n",
            "[ORIGINAL] Ep 65/100 | Reward: 210.0\n",
            "[ORIGINAL] Ep 66/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 67/100 | Reward: 378.0\n",
            "[ORIGINAL] Ep 68/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 69/100 | Reward: 315.0\n",
            "[ORIGINAL] Ep 70/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 71/100 | Reward: 294.0\n",
            "[ORIGINAL] Ep 72/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 73/100 | Reward: 420.0\n",
            "[ORIGINAL] Ep 74/100 | Reward: 378.0\n",
            "[ORIGINAL] Ep 75/100 | Reward: 378.0\n",
            "[ORIGINAL] Ep 76/100 | Reward: 336.0\n",
            "[ORIGINAL] Ep 77/100 | Reward: 252.0\n",
            "[ORIGINAL] Ep 78/100 | Reward: 273.0\n",
            "[ORIGINAL] Ep 79/100 | Reward: 336.0\n",
            "[ORIGINAL] Ep 80/100 | Reward: 294.0\n",
            "[ORIGINAL] Ep 81/100 | Reward: 294.0\n",
            "[ORIGINAL] Ep 82/100 | Reward: 357.0\n",
            "[ORIGINAL] Ep 83/100 | Reward: 231.0\n",
            "[ORIGINAL] Ep 84/100 | Reward: 273.0\n",
            "[ORIGINAL] Ep 85/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 86/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 87/100 | Reward: 462.0\n",
            "[ORIGINAL] Ep 88/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 89/100 | Reward: 231.0\n",
            "[ORIGINAL] Ep 90/100 | Reward: 378.0\n",
            "[ORIGINAL] Ep 91/100 | Reward: 399.0\n",
            "[ORIGINAL] Ep 92/100 | Reward: 273.0\n",
            "[ORIGINAL] Ep 93/100 | Reward: 378.0\n",
            "[ORIGINAL] Ep 94/100 | Reward: 252.0\n",
            "[ORIGINAL] Ep 95/100 | Reward: 294.0\n",
            "[ORIGINAL] Ep 96/100 | Reward: 252.0\n",
            "[ORIGINAL] Ep 97/100 | Reward: 210.0\n",
            "[ORIGINAL] Ep 98/100 | Reward: 168.0\n",
            "[ORIGINAL] Ep 99/100 | Reward: 189.0\n",
            "[ORIGINAL] Ep 100/100 | Reward: 168.0\n",
            "‚úÖ Saved model: /content/drive/MyDrive/AI_capstone/Assault-v5_original_REINFORCE.pth\n",
            "[BASELINE] Ep 1/100 | Reward: 210.0\n",
            "[BASELINE] Ep 2/100 | Reward: 231.0\n",
            "[BASELINE] Ep 3/100 | Reward: 147.0\n",
            "[BASELINE] Ep 4/100 | Reward: 231.0\n",
            "[BASELINE] Ep 5/100 | Reward: 231.0\n",
            "[BASELINE] Ep 6/100 | Reward: 168.0\n",
            "[BASELINE] Ep 7/100 | Reward: 210.0\n",
            "[BASELINE] Ep 8/100 | Reward: 189.0\n",
            "[BASELINE] Ep 9/100 | Reward: 273.0\n",
            "[BASELINE] Ep 10/100 | Reward: 252.0\n",
            "[BASELINE] Ep 11/100 | Reward: 252.0\n",
            "[BASELINE] Ep 12/100 | Reward: 378.0\n",
            "[BASELINE] Ep 13/100 | Reward: 336.0\n",
            "[BASELINE] Ep 14/100 | Reward: 378.0\n",
            "[BASELINE] Ep 15/100 | Reward: 252.0\n",
            "[BASELINE] Ep 16/100 | Reward: 231.0\n",
            "[BASELINE] Ep 17/100 | Reward: 273.0\n",
            "[BASELINE] Ep 18/100 | Reward: 336.0\n",
            "[BASELINE] Ep 19/100 | Reward: 231.0\n",
            "[BASELINE] Ep 20/100 | Reward: 357.0\n",
            "[BASELINE] Ep 21/100 | Reward: 231.0\n",
            "[BASELINE] Ep 22/100 | Reward: 336.0\n",
            "[BASELINE] Ep 23/100 | Reward: 399.0\n",
            "[BASELINE] Ep 24/100 | Reward: 210.0\n",
            "[BASELINE] Ep 25/100 | Reward: 189.0\n",
            "[BASELINE] Ep 26/100 | Reward: 378.0\n",
            "[BASELINE] Ep 27/100 | Reward: 378.0\n",
            "[BASELINE] Ep 28/100 | Reward: 252.0\n",
            "[BASELINE] Ep 29/100 | Reward: 441.0\n",
            "[BASELINE] Ep 30/100 | Reward: 231.0\n",
            "[BASELINE] Ep 31/100 | Reward: 336.0\n",
            "[BASELINE] Ep 32/100 | Reward: 315.0\n",
            "[BASELINE] Ep 33/100 | Reward: 189.0\n",
            "[BASELINE] Ep 34/100 | Reward: 252.0\n",
            "[BASELINE] Ep 35/100 | Reward: 252.0\n",
            "[BASELINE] Ep 36/100 | Reward: 147.0\n",
            "[BASELINE] Ep 37/100 | Reward: 357.0\n",
            "[BASELINE] Ep 38/100 | Reward: 378.0\n",
            "[BASELINE] Ep 39/100 | Reward: 357.0\n",
            "[BASELINE] Ep 40/100 | Reward: 252.0\n",
            "[BASELINE] Ep 41/100 | Reward: 294.0\n",
            "[BASELINE] Ep 42/100 | Reward: 189.0\n",
            "[BASELINE] Ep 43/100 | Reward: 252.0\n",
            "[BASELINE] Ep 44/100 | Reward: 399.0\n",
            "[BASELINE] Ep 45/100 | Reward: 399.0\n",
            "[BASELINE] Ep 46/100 | Reward: 231.0\n",
            "[BASELINE] Ep 47/100 | Reward: 189.0\n",
            "[BASELINE] Ep 48/100 | Reward: 336.0\n",
            "[BASELINE] Ep 49/100 | Reward: 420.0\n",
            "[BASELINE] Ep 50/100 | Reward: 147.0\n",
            "[BASELINE] Ep 51/100 | Reward: 315.0\n",
            "[BASELINE] Ep 52/100 | Reward: 441.0\n",
            "[BASELINE] Ep 53/100 | Reward: 273.0\n",
            "[BASELINE] Ep 54/100 | Reward: 231.0\n",
            "[BASELINE] Ep 55/100 | Reward: 294.0\n",
            "[BASELINE] Ep 56/100 | Reward: 231.0\n",
            "[BASELINE] Ep 57/100 | Reward: 399.0\n",
            "[BASELINE] Ep 58/100 | Reward: 357.0\n",
            "[BASELINE] Ep 59/100 | Reward: 231.0\n",
            "[BASELINE] Ep 60/100 | Reward: 336.0\n",
            "[BASELINE] Ep 61/100 | Reward: 189.0\n",
            "[BASELINE] Ep 62/100 | Reward: 483.0\n",
            "[BASELINE] Ep 63/100 | Reward: 252.0\n",
            "[BASELINE] Ep 64/100 | Reward: 273.0\n",
            "[BASELINE] Ep 65/100 | Reward: 378.0\n",
            "[BASELINE] Ep 66/100 | Reward: 168.0\n",
            "[BASELINE] Ep 67/100 | Reward: 357.0\n",
            "[BASELINE] Ep 68/100 | Reward: 294.0\n",
            "[BASELINE] Ep 69/100 | Reward: 189.0\n",
            "[BASELINE] Ep 70/100 | Reward: 189.0\n",
            "[BASELINE] Ep 71/100 | Reward: 294.0\n",
            "[BASELINE] Ep 72/100 | Reward: 231.0\n",
            "[BASELINE] Ep 73/100 | Reward: 273.0\n",
            "[BASELINE] Ep 74/100 | Reward: 420.0\n",
            "[BASELINE] Ep 75/100 | Reward: 252.0\n",
            "[BASELINE] Ep 76/100 | Reward: 273.0\n",
            "[BASELINE] Ep 77/100 | Reward: 357.0\n",
            "[BASELINE] Ep 78/100 | Reward: 378.0\n",
            "[BASELINE] Ep 79/100 | Reward: 399.0\n",
            "[BASELINE] Ep 80/100 | Reward: 252.0\n",
            "[BASELINE] Ep 81/100 | Reward: 315.0\n",
            "[BASELINE] Ep 82/100 | Reward: 336.0\n",
            "[BASELINE] Ep 83/100 | Reward: 315.0\n",
            "[BASELINE] Ep 84/100 | Reward: 336.0\n",
            "[BASELINE] Ep 85/100 | Reward: 378.0\n",
            "[BASELINE] Ep 86/100 | Reward: 252.0\n",
            "[BASELINE] Ep 87/100 | Reward: 357.0\n",
            "[BASELINE] Ep 88/100 | Reward: 294.0\n",
            "[BASELINE] Ep 89/100 | Reward: 357.0\n",
            "[BASELINE] Ep 90/100 | Reward: 294.0\n",
            "[BASELINE] Ep 91/100 | Reward: 462.0\n",
            "[BASELINE] Ep 92/100 | Reward: 462.0\n",
            "[BASELINE] Ep 93/100 | Reward: 315.0\n",
            "[BASELINE] Ep 94/100 | Reward: 336.0\n",
            "[BASELINE] Ep 95/100 | Reward: 231.0\n",
            "[BASELINE] Ep 96/100 | Reward: 399.0\n",
            "[BASELINE] Ep 97/100 | Reward: 336.0\n",
            "[BASELINE] Ep 98/100 | Reward: 294.0\n",
            "[BASELINE] Ep 99/100 | Reward: 147.0\n",
            "[BASELINE] Ep 100/100 | Reward: 441.0\n",
            "‚úÖ Saved model: /content/drive/MyDrive/AI_capstone/Assault-v5_baseline_REINFORCE.pth\n",
            "[ADVANTAGE] Ep 1/100 | Reward: 336.0\n",
            "[ADVANTAGE] Ep 2/100 | Reward: 210.0\n",
            "[ADVANTAGE] Ep 3/100 | Reward: 189.0\n",
            "[ADVANTAGE] Ep 4/100 | Reward: 210.0\n",
            "[ADVANTAGE] Ep 5/100 | Reward: 231.0\n",
            "[ADVANTAGE] Ep 6/100 | Reward: 273.0\n",
            "[ADVANTAGE] Ep 7/100 | Reward: 273.0\n",
            "[ADVANTAGE] Ep 8/100 | Reward: 336.0\n",
            "[ADVANTAGE] Ep 9/100 | Reward: 126.0\n",
            "[ADVANTAGE] Ep 10/100 | Reward: 189.0\n",
            "[ADVANTAGE] Ep 11/100 | Reward: 378.0\n",
            "[ADVANTAGE] Ep 12/100 | Reward: 252.0\n",
            "[ADVANTAGE] Ep 13/100 | Reward: 273.0\n",
            "[ADVANTAGE] Ep 14/100 | Reward: 210.0\n",
            "[ADVANTAGE] Ep 15/100 | Reward: 273.0\n",
            "[ADVANTAGE] Ep 16/100 | Reward: 189.0\n",
            "[ADVANTAGE] Ep 17/100 | Reward: 168.0\n",
            "[ADVANTAGE] Ep 18/100 | Reward: 252.0\n",
            "[ADVANTAGE] Ep 19/100 | Reward: 210.0\n",
            "[ADVANTAGE] Ep 20/100 | Reward: 273.0\n",
            "[ADVANTAGE] Ep 21/100 | Reward: 189.0\n",
            "[ADVANTAGE] Ep 22/100 | Reward: 42.0\n",
            "[ADVANTAGE] Ep 23/100 | Reward: 189.0\n",
            "[ADVANTAGE] Ep 24/100 | Reward: 231.0\n",
            "[ADVANTAGE] Ep 25/100 | Reward: 189.0\n",
            "[ADVANTAGE] Ep 26/100 | Reward: 231.0\n",
            "[ADVANTAGE] Ep 27/100 | Reward: 294.0\n",
            "[ADVANTAGE] Ep 28/100 | Reward: 294.0\n",
            "[ADVANTAGE] Ep 29/100 | Reward: 189.0\n",
            "[ADVANTAGE] Ep 30/100 | Reward: 294.0\n",
            "[ADVANTAGE] Ep 31/100 | Reward: 273.0\n",
            "[ADVANTAGE] Ep 32/100 | Reward: 147.0\n",
            "[ADVANTAGE] Ep 33/100 | Reward: 147.0\n",
            "[ADVANTAGE] Ep 34/100 | Reward: 126.0\n",
            "[ADVANTAGE] Ep 35/100 | Reward: 210.0\n",
            "[ADVANTAGE] Ep 36/100 | Reward: 210.0\n",
            "[ADVANTAGE] Ep 37/100 | Reward: 210.0\n",
            "[ADVANTAGE] Ep 38/100 | Reward: 273.0\n",
            "[ADVANTAGE] Ep 39/100 | Reward: 189.0\n",
            "[ADVANTAGE] Ep 40/100 | Reward: 189.0\n",
            "[ADVANTAGE] Ep 41/100 | Reward: 189.0\n",
            "[ADVANTAGE] Ep 42/100 | Reward: 315.0\n",
            "[ADVANTAGE] Ep 43/100 | Reward: 168.0\n",
            "[ADVANTAGE] Ep 44/100 | Reward: 126.0\n",
            "[ADVANTAGE] Ep 45/100 | Reward: 273.0\n",
            "[ADVANTAGE] Ep 46/100 | Reward: 273.0\n",
            "[ADVANTAGE] Ep 47/100 | Reward: 294.0\n",
            "[ADVANTAGE] Ep 48/100 | Reward: 189.0\n",
            "[ADVANTAGE] Ep 49/100 | Reward: 168.0\n",
            "[ADVANTAGE] Ep 50/100 | Reward: 189.0\n",
            "[ADVANTAGE] Ep 51/100 | Reward: 189.0\n",
            "[ADVANTAGE] Ep 52/100 | Reward: 357.0\n",
            "[ADVANTAGE] Ep 53/100 | Reward: 252.0\n",
            "[ADVANTAGE] Ep 54/100 | Reward: 210.0\n",
            "[ADVANTAGE] Ep 55/100 | Reward: 336.0\n",
            "[ADVANTAGE] Ep 56/100 | Reward: 483.0\n",
            "[ADVANTAGE] Ep 57/100 | Reward: 168.0\n",
            "[ADVANTAGE] Ep 58/100 | Reward: 315.0\n",
            "[ADVANTAGE] Ep 59/100 | Reward: 357.0\n",
            "[ADVANTAGE] Ep 60/100 | Reward: 315.0\n",
            "[ADVANTAGE] Ep 61/100 | Reward: 189.0\n",
            "[ADVANTAGE] Ep 62/100 | Reward: 399.0\n",
            "[ADVANTAGE] Ep 63/100 | Reward: 399.0\n",
            "[ADVANTAGE] Ep 64/100 | Reward: 231.0\n",
            "[ADVANTAGE] Ep 65/100 | Reward: 420.0\n",
            "[ADVANTAGE] Ep 66/100 | Reward: 210.0\n",
            "[ADVANTAGE] Ep 67/100 | Reward: 336.0\n",
            "[ADVANTAGE] Ep 68/100 | Reward: 357.0\n",
            "[ADVANTAGE] Ep 69/100 | Reward: 336.0\n",
            "[ADVANTAGE] Ep 70/100 | Reward: 399.0\n",
            "[ADVANTAGE] Ep 71/100 | Reward: 336.0\n",
            "[ADVANTAGE] Ep 72/100 | Reward: 231.0\n",
            "[ADVANTAGE] Ep 73/100 | Reward: 336.0\n",
            "[ADVANTAGE] Ep 74/100 | Reward: 357.0\n",
            "[ADVANTAGE] Ep 75/100 | Reward: 315.0\n",
            "[ADVANTAGE] Ep 76/100 | Reward: 462.0\n",
            "[ADVANTAGE] Ep 77/100 | Reward: 168.0\n",
            "[ADVANTAGE] Ep 78/100 | Reward: 378.0\n",
            "[ADVANTAGE] Ep 79/100 | Reward: 336.0\n",
            "[ADVANTAGE] Ep 80/100 | Reward: 273.0\n",
            "[ADVANTAGE] Ep 81/100 | Reward: 378.0\n",
            "[ADVANTAGE] Ep 82/100 | Reward: 147.0\n",
            "[ADVANTAGE] Ep 83/100 | Reward: 399.0\n",
            "[ADVANTAGE] Ep 84/100 | Reward: 210.0\n",
            "[ADVANTAGE] Ep 85/100 | Reward: 210.0\n",
            "[ADVANTAGE] Ep 86/100 | Reward: 357.0\n",
            "[ADVANTAGE] Ep 87/100 | Reward: 189.0\n",
            "[ADVANTAGE] Ep 88/100 | Reward: 357.0\n",
            "[ADVANTAGE] Ep 89/100 | Reward: 252.0\n",
            "[ADVANTAGE] Ep 90/100 | Reward: 378.0\n",
            "[ADVANTAGE] Ep 91/100 | Reward: 357.0\n",
            "[ADVANTAGE] Ep 92/100 | Reward: 336.0\n",
            "[ADVANTAGE] Ep 93/100 | Reward: 378.0\n",
            "[ADVANTAGE] Ep 94/100 | Reward: 441.0\n",
            "[ADVANTAGE] Ep 95/100 | Reward: 378.0\n",
            "[ADVANTAGE] Ep 96/100 | Reward: 462.0\n",
            "[ADVANTAGE] Ep 97/100 | Reward: 378.0\n",
            "[ADVANTAGE] Ep 98/100 | Reward: 273.0\n",
            "[ADVANTAGE] Ep 99/100 | Reward: 420.0\n",
            "[ADVANTAGE] Ep 100/100 | Reward: 294.0\n",
            "‚úÖ Saved model: /content/drive/MyDrive/AI_capstone/Assault-v5_advantage_REINFORCE.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rewards_original = evaluate_reinforce(\n",
        "    \"ALE/Assault-v5\",\n",
        "    f\"{Base_dir}Assault-v5_original_REINFORCE.pth\",\n",
        "    variant=\"original\"\n",
        ")\n",
        "\n",
        "rewards_baseline = evaluate_reinforce(\n",
        "    \"ALE/Assault-v5\",\n",
        "    \"Assault-v5_baseline_REINFORCE.pth\",\n",
        "    variant=\"baseline\"\n",
        ")\n",
        "\n",
        "rewards_advantage = evaluate_reinforce(\n",
        "    \"ALE/Assault-v5\",\n",
        "    \"Assault-v5_advantage_REINFORCE.pth\",\n",
        "    variant=\"advantage\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "D6Xnd9_NwAvs",
        "outputId": "8b9fc942-c1a6-48e7-d78d-7a44806c5862",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Assault-v5_original_REINFORCE.pth'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-215b0c584ac3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m rewards_original = evaluate_reinforce(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"ALE/Assault-v5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"Assault-v5_original_REINFORCE.pth\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvariant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"original\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-12-4abd4365d7e3>\u001b[0m in \u001b[0;36mevaluate_reinforce\u001b[0;34m(env_id, model_path, episodes, variant)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mact_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNNREINFORCEPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Assault-v5_original_REINFORCE.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Average Reward:\")\n",
        "print(f\"Original  : {np.mean(rewards_original):.2f}\")\n",
        "print(f\"Baseline  : {np.mean(rewards_baseline):.2f}\")\n",
        "print(f\"Advantage : {np.mean(rewards_advantage):.2f}\")\n",
        "\n",
        "plot_rewards({\n",
        "    \"original_REINFORCE\": rewards_original,\n",
        "    \"baseline_REINFORCE\": rewards_baseline,\n",
        "    \"advantage_REINFORCE\": rewards_advantage\n",
        "})"
      ],
      "metadata": {
        "id": "hdf8EfdbnZ6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Action constraint"
      ],
      "metadata": {
        "id": "Liz-XwbscX25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "class CarRacingSteeringConstraint(gym.ActionWrapper):\n",
        "    def __init__(self, env, mini=-0.8, maxi=0.8):\n",
        "        super().__init__(env)\n",
        "        self.min_steering = mini\n",
        "        self.max_steering = maxi\n",
        "\n",
        "    def action(self, action):\n",
        "        # Clip only the steering (index 0), pass gas/brake unchanged\n",
        "        action[0] = np.clip(action[0], self.min_steering, self.max_steering)\n",
        "        return action\n"
      ],
      "metadata": {
        "id": "RJNRVcHLcaUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "class BipedalWalkerActionConstraint(gym.ActionWrapper):\n",
        "    def __init__(self, env, mini=-0.8, maxi=0.8):\n",
        "        super().__init__(env)\n",
        "        self.min_action = min_action\n",
        "        self.max_action = max_action\n",
        "\n",
        "    def action(self, action):\n",
        "        return np.clip(action, self.min_action, self.max_action)\n"
      ],
      "metadata": {
        "id": "vmVpSNhzfBuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wrap_with_constraints(env, env_id, mini = -1, maxi = 1):\n",
        "    if \"CarRacing\" in env_id:\n",
        "        return CarRacingSteeringConstraint(env, mini, maxi)\n",
        "    if \"BipedalWalker\" in env_id:\n",
        "        return BipedalWalkerActionConstraint(env, mini, maxi)\n",
        "    return env  # default: no constraint\n"
      ],
      "metadata": {
        "id": "LO0VG-12iC8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2 : model-free and action constraint"
      ],
      "metadata": {
        "id": "5jV_LyqHnFYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO, A2C, SAC\n",
        "from stable_baselines3.common.env_util import make_vec_env"
      ],
      "metadata": {
        "id": "aHmb31RZdkjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.logger import configure\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "import os\n",
        "\n",
        "Base_dir = \"/content/drive/MyDrive/AI_capstone/\"\n",
        "\n",
        "def train_sb3(algo, env_id, total_timesteps=100_000, mini=-1, maxi=1):\n",
        "    policy = \"CnnPolicy\" if \"ALE\" in env_id else \"MlpPolicy\"\n",
        "    algo_name = algo.__name__\n",
        "\n",
        "    log_dir = f\"{Base_dir}/logs/{env_id.replace('/', '_')}_{algo_name}_min{mini}_max{maxi}\"\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "    def make_env():\n",
        "        env = gym.make(env_id)\n",
        "        env = wrap_with_constraints(env, env_id, mini, maxi)\n",
        "        return Monitor(env)\n",
        "\n",
        "    env = make_vec_env(make_env, n_envs=1)\n",
        "\n",
        "    model = algo(policy, env, verbose=1)\n",
        "    model.set_logger(configure(log_dir, [\"stdout\", \"csv\", \"tensorboard\"]))\n",
        "\n",
        "    model.learn(total_timesteps=total_timesteps)\n",
        "\n",
        "    model_path = f\"{Base_dir}/models/{env_id.replace('/', '_')}_{algo_name}_min{mini}_max{maxi}.zip\"\n",
        "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "    model.save(model_path)\n",
        "\n",
        "    print(f\"‚úÖ Model saved to: {model_path}\")\n",
        "    print(f\"üìÅ Logs stored in: {log_dir}\")\n"
      ],
      "metadata": {
        "id": "6DxfLou1cKeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "\n",
        "def evaluate_sb3(model_class, model_path, env_id, episodes=10, mini=-1, maxi=1):\n",
        "    model = model_class.load(model_path)\n",
        "\n",
        "    # Build video directory with constraint values\n",
        "    algo = model_class.__name__\n",
        "    video_dir = f\"{Base_dir}/videos/{env_id.replace('/', '_')}_{algo}_min{mini}_max{maxi}\"\n",
        "    os.makedirs(video_dir, exist_ok=True)\n",
        "\n",
        "    # Apply constraint wrapper if needed\n",
        "    env = gym.make(env_id, render_mode=\"rgb_array\")\n",
        "    env = wrap_with_constraints(env, env_id, mini, maxi)\n",
        "\n",
        "    # Record only the first episode\n",
        "    env = RecordVideo(\n",
        "        env,\n",
        "        video_dir=video_dir,\n",
        "        episode_trigger=lambda ep: ep == 0,\n",
        "        name_prefix=f\"{env_id.replace('/', '_')}_{algo}_min{mini}_max{maxi}\"\n",
        "    )\n",
        "\n",
        "    print(f\"üé• Recording to {video_dir}\")\n",
        "\n",
        "    rewards = []\n",
        "    for ep in range(episodes):\n",
        "        obs, _ = env.reset()\n",
        "        done, total_reward = False, 0\n",
        "        while not done:\n",
        "            action, _ = model.predict(obs)\n",
        "            obs, reward, done, truncated, _ = env.step(action)\n",
        "            total_reward += reward\n",
        "        rewards.append(total_reward)\n",
        "        print(f\"[EVAL] Episode {ep+1} | Reward: {total_reward:.2f}\")\n",
        "\n",
        "    env.close()\n",
        "    print(f\"‚úÖ Finished. Video: {video_dir}\")\n",
        "    return rewards\n"
      ],
      "metadata": {
        "id": "VPRNVtlHnUkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### non-Action-Constraint\n",
        "\n"
      ],
      "metadata": {
        "id": "z2xbYTzqj1kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sb3(PPO, \"CarRacing-v3\", total_timesteps=100_000, mini=-1, maxi=1)"
      ],
      "metadata": {
        "id": "gqdKLDbZj8h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sb3(A2C, \"CarRacing-v3\", total_timesteps=100_000, mini=-1, maxi=1)"
      ],
      "metadata": {
        "id": "2sK-vORTokt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_rewards = evaluate_sb3(\n",
        "    PPO,\n",
        "    model_path=\"/content/drive/MyDrive/AI_capstone/models/CarRacing-v3_PPO_min-1_max1.zip\",\n",
        "    env_id=\"CarRacing-v3\",\n",
        "    mini=-1,\n",
        "    maxi=1\n",
        ")"
      ],
      "metadata": {
        "id": "MrhHDGSfcvYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a2c_rewards = evaluate_sb3(\n",
        "    A2C,\n",
        "    model_path=\"/content/drive/MyDrive/AI_capstone/models/CarRacing-v3_A2C_min-1_max1.zip\",\n",
        "    env_id=\"CarRacing-v3\",\n",
        "    mini=-1,\n",
        "    maxi=1\n",
        ")"
      ],
      "metadata": {
        "id": "b-zTst-7sIs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot results\n",
        "plot_rewards({\n",
        "    \"PPO\": ppo_rewards,\n",
        "    \"A2C\": a2c_rewards,\n",
        "})"
      ],
      "metadata": {
        "id": "QrdMTPufcuOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Car Racing"
      ],
      "metadata": {
        "id": "SVrgV5QOvrqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Action-Constraint (test-time)"
      ],
      "metadata": {
        "id": "mI9PhSzLopy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_rewards_7 = evaluate_sb3(\n",
        "    PPO,\n",
        "    model_path=\"/content/drive/MyDrive/AI_capstone/models/CarRacing-v3_PPO_min-1_max1.zip\",\n",
        "    env_id=\"CarRacing-v3\",\n",
        "    mini=-0.7,\n",
        "    maxi=0.7\n",
        ")"
      ],
      "metadata": {
        "id": "HYGh5DrMsPMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a2c_rewards_7 = evaluate_sb3(\n",
        "    A2C,\n",
        "    model_path=\"/content/drive/MyDrive/AI_capstone/models/CarRacing-v3_A2C_min-1_max1.zip\",\n",
        "    env_id=\"CarRacing-v3\",\n",
        "    mini=-0.7,\n",
        "    maxi=0.7\n",
        ")\n"
      ],
      "metadata": {
        "id": "URNt_su-siw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot results\n",
        "plot_rewards({\n",
        "    \"PPO\": ppo_rewards_7,\n",
        "    \"A2C\": a2c_rewards_7,\n",
        "})"
      ],
      "metadata": {
        "id": "jSgiLnyns23I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Action-Constraint (train+test time)"
      ],
      "metadata": {
        "id": "0n8t4RVYunRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sb3(PPO, \"CarRacing-v3\", total_timesteps=100_000, mini=-0.7, maxi=0.7)"
      ],
      "metadata": {
        "id": "2XSsxjVnuxs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sb3(A2C, \"CarRacing-v3\", total_timesteps=100_000, mini=-0.7, maxi=0.7)"
      ],
      "metadata": {
        "id": "7MarTUVCutaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_rewards_7 = evaluate_sb3(\n",
        "    PPO,\n",
        "    model_path=\"/content/drive/MyDrive/AI_capstone/models/CarRacing-v3_PPO_min-0.7_max0.7.zip\",\n",
        "    env_id=\"CarRacing-v3\",\n",
        "    mini=-0.7,\n",
        "    maxi=0.7\n",
        ")"
      ],
      "metadata": {
        "id": "TePrlGjXu386"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a2c_rewards_7 = evaluate_sb3(\n",
        "    A2C,\n",
        "    model_path=\"/content/drive/MyDrive/AI_capstone/models/CarRacing-v3_A2C_min-0.7_max0.7.zip\",\n",
        "    env_id=\"CarRacing-v3\",\n",
        "    mini=-0.7,\n",
        "    maxi=0.7\n",
        ")"
      ],
      "metadata": {
        "id": "0KCDL2d2u5eT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BipedalWalker-v3"
      ],
      "metadata": {
        "id": "RgY1tQZcvyFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### no-Action-constraint"
      ],
      "metadata": {
        "id": "sOhEbFWuv5s-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sb3(PPO, \"BipedalWalker-v3\", total_timesteps=100_000, mini=-1, maxi=1)"
      ],
      "metadata": {
        "id": "24dwPsAOv4im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sb3(A2C, \"BipedalWalker-v3\", total_timesteps=100_000, mini=-1, maxi=1)"
      ],
      "metadata": {
        "id": "HFQkZBKlwCTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_rewards = evaluate_sb3(\n",
        "    PPO,\n",
        "    model_path=\"/content/drive/MyDrive/AI_capstone/models/BipedalWalker-v3_PPO_min-1_max1.zip\",\n",
        "    env_id=\"BipedalWalker-v3\",\n",
        "    mini=-1,\n",
        "    maxi=1\n",
        ")"
      ],
      "metadata": {
        "id": "SWXdpGfBwIDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_rewards = evaluate_sb3(\n",
        "    A2C,\n",
        "    model_path=\"/content/drive/MyDrive/AI_capstone/models/BipedalWalker-v3_A2C_min-1_max1.zip\",\n",
        "    env_id=\"BipedalWalker-v3\",\n",
        "    mini=-1,\n",
        "    maxi=1\n",
        ")"
      ],
      "metadata": {
        "id": "BnV7SU0EwY2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot results\n",
        "plot_rewards({\n",
        "    \"PPO\": ppo_rewards,\n",
        "    \"A2C\": a2c_rewards,\n",
        "})"
      ],
      "metadata": {
        "id": "mFx930ElwiN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test-time Action constraint"
      ],
      "metadata": {
        "id": "zLFONz_nwj_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_rewards_7 = evaluate_sb3(\n",
        "    PPO,\n",
        "    model_path=\"/content/drive/MyDrive/AI_capstone/models/BipedalWalker-v3_PPO_min-1_max1.zip\",\n",
        "    env_id=\"BipedalWalker-v3\",\n",
        "    mini=-0.7,\n",
        "    maxi=0.7\n",
        ")"
      ],
      "metadata": {
        "id": "FrN1tZ3hwuMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a2c_rewards_7 = evaluate_sb3(\n",
        "    A2C,\n",
        "    model_path=\"/content/drive/MyDrive/AI_capstone/models/BipedalWalker-v3_A2C_min-1_max1.zip\",\n",
        "    env_id=\"BipedalWalker-v3\",\n",
        "    mini=-0.7,\n",
        "    maxi=0.7\n",
        ")\n"
      ],
      "metadata": {
        "id": "efHyCxJRwxv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot results\n",
        "plot_rewards({\n",
        "    \"PPO\": ppo_rewards_7,\n",
        "    \"A2C\": a2c_rewards_7,\n",
        "})"
      ],
      "metadata": {
        "id": "OEV878pjw0SG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train-test-time Action constraint"
      ],
      "metadata": {
        "id": "EyhFfxE1xG1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sb3(A2C, \"CarRacing-v3\", total_timesteps=100_000, mini=-0.7, maxi=0.7)"
      ],
      "metadata": {
        "id": "iF1wi36exK1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sb3(A2C, \"CarRacing-v3\", total_timesteps=100_000, mini=-0.7, maxi=0.7)"
      ],
      "metadata": {
        "id": "jUKY99OaxLps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_rewards_7 = evaluate_sb3(\n",
        "    PPO,\n",
        "    model_path=\"/content/drive/MyDrive/AI_capstone/models/BipedalWalker-v3_PPO_min-1_max1.zip\",\n",
        "    env_id=\"BipedalWalker-v3\",\n",
        "    mini=-0.7,\n",
        "    maxi=0.7\n",
        ")"
      ],
      "metadata": {
        "id": "-DNksJ6axPZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a2c_rewards_7 = evaluate_sb3(\n",
        "    A2C,\n",
        "    model_path=\"/content/drive/MyDrive/AI_capstone/models/BipedalWalker-v3_A2C_min-1_max1.zip\",\n",
        "    env_id=\"BipedalWalker-v3\",\n",
        "    mini=-0.7,\n",
        "    maxi=0.7\n",
        ")\n"
      ],
      "metadata": {
        "id": "h1Xsy3GAxP7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot results\n",
        "plot_rewards({\n",
        "    \"PPO\": ppo_rewards_7,\n",
        "    \"A2C\": a2c_rewards_7,\n",
        "})"
      ],
      "metadata": {
        "id": "JRlF3uMmxUCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Others"
      ],
      "metadata": {
        "id": "O2cCPyQAsP5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "envs_discrete = [\"ALE/Assault-v5\"]\n",
        "# envs_continuous = [\"CarRacing-v2\", \"BipedalWalker-v3\"]\n",
        "\n",
        "print(\"\\n=== TRAINING PPO ===\")\n",
        "for env_id in envs_discrete:\n",
        "    train_sb3(PPO, env_id)\n",
        "\n",
        "print(\"\\n=== TRAINING A2C ===\")\n",
        "for env_id in envs_discrete:\n",
        "    train_sb3(A2C, env_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0PuzYjPKbwcX",
        "outputId": "be092953-c719-4518-a430-ed2a52d71c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TRAINING PPO ===\n",
            "Using cuda device\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 594      |\n",
            "|    ep_rew_mean     | 259      |\n",
            "| time/              |          |\n",
            "|    fps             | 290      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 7        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 574         |\n",
            "|    ep_rew_mean          | 264         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 204         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 19          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011813848 |\n",
            "|    clip_fraction        | 0.21        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.93       |\n",
            "|    explained_variance   | 0.000423    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.45        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0161     |\n",
            "|    value_loss           | 37.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 583         |\n",
            "|    ep_rew_mean          | 275         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 190         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 32          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028270531 |\n",
            "|    clip_fraction        | 0.215       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.91       |\n",
            "|    explained_variance   | 0.0213      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.88        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0118     |\n",
            "|    value_loss           | 26.6        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 576        |\n",
            "|    ep_rew_mean          | 264        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 181        |\n",
            "|    iterations           | 4          |\n",
            "|    time_elapsed         | 45         |\n",
            "|    total_timesteps      | 8192       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03502758 |\n",
            "|    clip_fraction        | 0.329      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.88      |\n",
            "|    explained_variance   | 0.193      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.19       |\n",
            "|    n_updates            | 30         |\n",
            "|    policy_gradient_loss | -0.0108    |\n",
            "|    value_loss           | 19.7       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 585        |\n",
            "|    ep_rew_mean          | 256        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 178        |\n",
            "|    iterations           | 5          |\n",
            "|    time_elapsed         | 57         |\n",
            "|    total_timesteps      | 10240      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03533072 |\n",
            "|    clip_fraction        | 0.328      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.84      |\n",
            "|    explained_variance   | 0.317      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.44       |\n",
            "|    n_updates            | 40         |\n",
            "|    policy_gradient_loss | -0.0103    |\n",
            "|    value_loss           | 16.2       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 590         |\n",
            "|    ep_rew_mean          | 260         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 176         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 69          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.039305773 |\n",
            "|    clip_fraction        | 0.375       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.79       |\n",
            "|    explained_variance   | 0.533       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.69        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0122     |\n",
            "|    value_loss           | 18.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 583         |\n",
            "|    ep_rew_mean          | 263         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 175         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 81          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.039845098 |\n",
            "|    clip_fraction        | 0.376       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.76       |\n",
            "|    explained_variance   | 0.416       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.933       |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0169     |\n",
            "|    value_loss           | 17.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 585         |\n",
            "|    ep_rew_mean          | 264         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 174         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 93          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.046070173 |\n",
            "|    clip_fraction        | 0.445       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.7        |\n",
            "|    explained_variance   | 0.314       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.01        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.015      |\n",
            "|    value_loss           | 13.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 589         |\n",
            "|    ep_rew_mean          | 266         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 173         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 106         |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.051291965 |\n",
            "|    clip_fraction        | 0.42        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.71       |\n",
            "|    explained_variance   | 0.587       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.737       |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0136     |\n",
            "|    value_loss           | 13.8        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 587        |\n",
            "|    ep_rew_mean          | 269        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 172        |\n",
            "|    iterations           | 10         |\n",
            "|    time_elapsed         | 118        |\n",
            "|    total_timesteps      | 20480      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06277351 |\n",
            "|    clip_fraction        | 0.423      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.67      |\n",
            "|    explained_variance   | 0.619      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.42       |\n",
            "|    n_updates            | 90         |\n",
            "|    policy_gradient_loss | -0.0167    |\n",
            "|    value_loss           | 12.1       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 596         |\n",
            "|    ep_rew_mean          | 281         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 172         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 130         |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.046930768 |\n",
            "|    clip_fraction        | 0.436       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.65       |\n",
            "|    explained_variance   | 0.743       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.564       |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0216     |\n",
            "|    value_loss           | 11.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 590         |\n",
            "|    ep_rew_mean          | 278         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 171         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 143         |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.059890922 |\n",
            "|    clip_fraction        | 0.436       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.64       |\n",
            "|    explained_variance   | 0.608       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.77        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0158     |\n",
            "|    value_loss           | 13.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 589         |\n",
            "|    ep_rew_mean          | 276         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 171         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 155         |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.066682555 |\n",
            "|    clip_fraction        | 0.474       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.64       |\n",
            "|    explained_variance   | 0.596       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.76        |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0181     |\n",
            "|    value_loss           | 13.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 594         |\n",
            "|    ep_rew_mean          | 278         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 170         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 167         |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.062007055 |\n",
            "|    clip_fraction        | 0.468       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.64       |\n",
            "|    explained_variance   | 0.695       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.784       |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0188     |\n",
            "|    value_loss           | 11.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 600         |\n",
            "|    ep_rew_mean          | 278         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 170         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 180         |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.057707027 |\n",
            "|    clip_fraction        | 0.472       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.61       |\n",
            "|    explained_variance   | 0.612       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.528       |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00986    |\n",
            "|    value_loss           | 9.92        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 594        |\n",
            "|    ep_rew_mean          | 276        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 170        |\n",
            "|    iterations           | 16         |\n",
            "|    time_elapsed         | 192        |\n",
            "|    total_timesteps      | 32768      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06358331 |\n",
            "|    clip_fraction        | 0.451      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.65      |\n",
            "|    explained_variance   | 0.683      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.935      |\n",
            "|    n_updates            | 150        |\n",
            "|    policy_gradient_loss | -0.0184    |\n",
            "|    value_loss           | 9.81       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 595         |\n",
            "|    ep_rew_mean          | 278         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 170         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 204         |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.051469382 |\n",
            "|    clip_fraction        | 0.455       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.68       |\n",
            "|    explained_variance   | 0.758       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.7         |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0262     |\n",
            "|    value_loss           | 11.1        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 603        |\n",
            "|    ep_rew_mean          | 285        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 170        |\n",
            "|    iterations           | 18         |\n",
            "|    time_elapsed         | 216        |\n",
            "|    total_timesteps      | 36864      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.05961851 |\n",
            "|    clip_fraction        | 0.477      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.65      |\n",
            "|    explained_variance   | 0.606      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.758      |\n",
            "|    n_updates            | 170        |\n",
            "|    policy_gradient_loss | -0.0173    |\n",
            "|    value_loss           | 12.5       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 610         |\n",
            "|    ep_rew_mean          | 287         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 169         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 229         |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.060107432 |\n",
            "|    clip_fraction        | 0.467       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.63       |\n",
            "|    explained_variance   | 0.599       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.731       |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.0157     |\n",
            "|    value_loss           | 14.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 610         |\n",
            "|    ep_rew_mean          | 289         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 169         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 241         |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.063966915 |\n",
            "|    clip_fraction        | 0.466       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.59       |\n",
            "|    explained_variance   | 0.649       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.756       |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0199     |\n",
            "|    value_loss           | 10.6        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 611        |\n",
            "|    ep_rew_mean          | 289        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 169        |\n",
            "|    iterations           | 21         |\n",
            "|    time_elapsed         | 253        |\n",
            "|    total_timesteps      | 43008      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07787679 |\n",
            "|    clip_fraction        | 0.511      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.62      |\n",
            "|    explained_variance   | 0.733      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1          |\n",
            "|    n_updates            | 200        |\n",
            "|    policy_gradient_loss | -0.0152    |\n",
            "|    value_loss           | 9.57       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 608         |\n",
            "|    ep_rew_mean          | 288         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 169         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 265         |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.053550802 |\n",
            "|    clip_fraction        | 0.494       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.6        |\n",
            "|    explained_variance   | 0.728       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.304       |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0218     |\n",
            "|    value_loss           | 9.56        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 611         |\n",
            "|    ep_rew_mean          | 289         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 169         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 278         |\n",
            "|    total_timesteps      | 47104       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.052233428 |\n",
            "|    clip_fraction        | 0.452       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.63       |\n",
            "|    explained_variance   | 0.749       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.22        |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.025      |\n",
            "|    value_loss           | 10.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 611         |\n",
            "|    ep_rew_mean          | 289         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 169         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 290         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.056016378 |\n",
            "|    clip_fraction        | 0.46        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.61       |\n",
            "|    explained_variance   | 0.81        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.63        |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.0284     |\n",
            "|    value_loss           | 9.19        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 611        |\n",
            "|    ep_rew_mean          | 287        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 169        |\n",
            "|    iterations           | 25         |\n",
            "|    time_elapsed         | 302        |\n",
            "|    total_timesteps      | 51200      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06411869 |\n",
            "|    clip_fraction        | 0.465      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.56      |\n",
            "|    explained_variance   | 0.785      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.692      |\n",
            "|    n_updates            | 240        |\n",
            "|    policy_gradient_loss | -0.0231    |\n",
            "|    value_loss           | 8.85       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 610        |\n",
            "|    ep_rew_mean          | 287        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 168        |\n",
            "|    iterations           | 26         |\n",
            "|    time_elapsed         | 315        |\n",
            "|    total_timesteps      | 53248      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.05693024 |\n",
            "|    clip_fraction        | 0.462      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.6       |\n",
            "|    explained_variance   | 0.792      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.613      |\n",
            "|    n_updates            | 250        |\n",
            "|    policy_gradient_loss | -0.0237    |\n",
            "|    value_loss           | 10.7       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 609        |\n",
            "|    ep_rew_mean          | 285        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 168        |\n",
            "|    iterations           | 27         |\n",
            "|    time_elapsed         | 327        |\n",
            "|    total_timesteps      | 55296      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.09052654 |\n",
            "|    clip_fraction        | 0.502      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.55      |\n",
            "|    explained_variance   | 0.762      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.798      |\n",
            "|    n_updates            | 260        |\n",
            "|    policy_gradient_loss | -0.0212    |\n",
            "|    value_loss           | 11         |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 610        |\n",
            "|    ep_rew_mean          | 284        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 168        |\n",
            "|    iterations           | 28         |\n",
            "|    time_elapsed         | 339        |\n",
            "|    total_timesteps      | 57344      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.05912876 |\n",
            "|    clip_fraction        | 0.489      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.65      |\n",
            "|    explained_variance   | 0.746      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.357      |\n",
            "|    n_updates            | 270        |\n",
            "|    policy_gradient_loss | -0.0324    |\n",
            "|    value_loss           | 7.65       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 608         |\n",
            "|    ep_rew_mean          | 283         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 168         |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 351         |\n",
            "|    total_timesteps      | 59392       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.057687353 |\n",
            "|    clip_fraction        | 0.444       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.59       |\n",
            "|    explained_variance   | 0.818       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.642       |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | -0.0304     |\n",
            "|    value_loss           | 8.27        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 609        |\n",
            "|    ep_rew_mean          | 284        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 168        |\n",
            "|    iterations           | 30         |\n",
            "|    time_elapsed         | 364        |\n",
            "|    total_timesteps      | 61440      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07575281 |\n",
            "|    clip_fraction        | 0.49       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.57      |\n",
            "|    explained_variance   | 0.733      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.558      |\n",
            "|    n_updates            | 290        |\n",
            "|    policy_gradient_loss | -0.0224    |\n",
            "|    value_loss           | 10.5       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 610         |\n",
            "|    ep_rew_mean          | 285         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 168         |\n",
            "|    iterations           | 31          |\n",
            "|    time_elapsed         | 376         |\n",
            "|    total_timesteps      | 63488       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.058322713 |\n",
            "|    clip_fraction        | 0.463       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.58       |\n",
            "|    explained_variance   | 0.789       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.431       |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | -0.0386     |\n",
            "|    value_loss           | 8.74        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 614        |\n",
            "|    ep_rew_mean          | 287        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 168        |\n",
            "|    iterations           | 32         |\n",
            "|    time_elapsed         | 388        |\n",
            "|    total_timesteps      | 65536      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.05874791 |\n",
            "|    clip_fraction        | 0.472      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.54      |\n",
            "|    explained_variance   | 0.766      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.294      |\n",
            "|    n_updates            | 310        |\n",
            "|    policy_gradient_loss | -0.0309    |\n",
            "|    value_loss           | 9.6        |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 614        |\n",
            "|    ep_rew_mean          | 289        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 168        |\n",
            "|    iterations           | 33         |\n",
            "|    time_elapsed         | 400        |\n",
            "|    total_timesteps      | 67584      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07168252 |\n",
            "|    clip_fraction        | 0.457      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.48      |\n",
            "|    explained_variance   | 0.762      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.618      |\n",
            "|    n_updates            | 320        |\n",
            "|    policy_gradient_loss | -0.0337    |\n",
            "|    value_loss           | 9.03       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 617         |\n",
            "|    ep_rew_mean          | 291         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 168         |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 413         |\n",
            "|    total_timesteps      | 69632       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.059628606 |\n",
            "|    clip_fraction        | 0.478       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.53       |\n",
            "|    explained_variance   | 0.729       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.511       |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | -0.0301     |\n",
            "|    value_loss           | 9.89        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 619        |\n",
            "|    ep_rew_mean          | 294        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 168        |\n",
            "|    iterations           | 35         |\n",
            "|    time_elapsed         | 425        |\n",
            "|    total_timesteps      | 71680      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06985642 |\n",
            "|    clip_fraction        | 0.47       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.47      |\n",
            "|    explained_variance   | 0.763      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.743      |\n",
            "|    n_updates            | 340        |\n",
            "|    policy_gradient_loss | -0.0305    |\n",
            "|    value_loss           | 10.8       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 618        |\n",
            "|    ep_rew_mean          | 294        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 168        |\n",
            "|    iterations           | 36         |\n",
            "|    time_elapsed         | 437        |\n",
            "|    total_timesteps      | 73728      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.09126645 |\n",
            "|    clip_fraction        | 0.517      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.45      |\n",
            "|    explained_variance   | 0.739      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.307      |\n",
            "|    n_updates            | 350        |\n",
            "|    policy_gradient_loss | -0.0355    |\n",
            "|    value_loss           | 7.9        |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 621        |\n",
            "|    ep_rew_mean          | 294        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 168        |\n",
            "|    iterations           | 37         |\n",
            "|    time_elapsed         | 449        |\n",
            "|    total_timesteps      | 75776      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07168646 |\n",
            "|    clip_fraction        | 0.481      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.47      |\n",
            "|    explained_variance   | 0.812      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.462      |\n",
            "|    n_updates            | 360        |\n",
            "|    policy_gradient_loss | -0.0315    |\n",
            "|    value_loss           | 8.2        |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 621        |\n",
            "|    ep_rew_mean          | 295        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 168        |\n",
            "|    iterations           | 38         |\n",
            "|    time_elapsed         | 461        |\n",
            "|    total_timesteps      | 77824      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.08815062 |\n",
            "|    clip_fraction        | 0.521      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.39      |\n",
            "|    explained_variance   | 0.812      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.52       |\n",
            "|    n_updates            | 370        |\n",
            "|    policy_gradient_loss | -0.024     |\n",
            "|    value_loss           | 8.21       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 622        |\n",
            "|    ep_rew_mean          | 297        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 168        |\n",
            "|    iterations           | 39         |\n",
            "|    time_elapsed         | 474        |\n",
            "|    total_timesteps      | 79872      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.08932131 |\n",
            "|    clip_fraction        | 0.462      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.43      |\n",
            "|    explained_variance   | 0.739      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.737      |\n",
            "|    n_updates            | 380        |\n",
            "|    policy_gradient_loss | -0.0225    |\n",
            "|    value_loss           | 11.6       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 625       |\n",
            "|    ep_rew_mean          | 299       |\n",
            "| time/                   |           |\n",
            "|    fps                  | 168       |\n",
            "|    iterations           | 40        |\n",
            "|    time_elapsed         | 486       |\n",
            "|    total_timesteps      | 81920     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0809042 |\n",
            "|    clip_fraction        | 0.482     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.37     |\n",
            "|    explained_variance   | 0.683     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.603     |\n",
            "|    n_updates            | 390       |\n",
            "|    policy_gradient_loss | -0.0364   |\n",
            "|    value_loss           | 10.5      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 626        |\n",
            "|    ep_rew_mean          | 298        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 168        |\n",
            "|    iterations           | 41         |\n",
            "|    time_elapsed         | 498        |\n",
            "|    total_timesteps      | 83968      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07964447 |\n",
            "|    clip_fraction        | 0.505      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.41      |\n",
            "|    explained_variance   | 0.506      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.373      |\n",
            "|    n_updates            | 400        |\n",
            "|    policy_gradient_loss | -0.0303    |\n",
            "|    value_loss           | 10.2       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 627         |\n",
            "|    ep_rew_mean          | 296         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 168         |\n",
            "|    iterations           | 42          |\n",
            "|    time_elapsed         | 510         |\n",
            "|    total_timesteps      | 86016       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.079029925 |\n",
            "|    clip_fraction        | 0.514       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.44       |\n",
            "|    explained_variance   | 0.707       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.427       |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | -0.0294     |\n",
            "|    value_loss           | 9.51        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 629        |\n",
            "|    ep_rew_mean          | 298        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 168        |\n",
            "|    iterations           | 43         |\n",
            "|    time_elapsed         | 523        |\n",
            "|    total_timesteps      | 88064      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07773518 |\n",
            "|    clip_fraction        | 0.492      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.36      |\n",
            "|    explained_variance   | 0.815      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.544      |\n",
            "|    n_updates            | 420        |\n",
            "|    policy_gradient_loss | -0.0286    |\n",
            "|    value_loss           | 9.89       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 626         |\n",
            "|    ep_rew_mean          | 297         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 168         |\n",
            "|    iterations           | 44          |\n",
            "|    time_elapsed         | 535         |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.090131804 |\n",
            "|    clip_fraction        | 0.522       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.43       |\n",
            "|    explained_variance   | 0.767       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.481       |\n",
            "|    n_updates            | 430         |\n",
            "|    policy_gradient_loss | -0.0318     |\n",
            "|    value_loss           | 9.4         |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 626        |\n",
            "|    ep_rew_mean          | 299        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 168        |\n",
            "|    iterations           | 45         |\n",
            "|    time_elapsed         | 547        |\n",
            "|    total_timesteps      | 92160      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.08589995 |\n",
            "|    clip_fraction        | 0.496      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.36      |\n",
            "|    explained_variance   | 0.805      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.556      |\n",
            "|    n_updates            | 440        |\n",
            "|    policy_gradient_loss | -0.0395    |\n",
            "|    value_loss           | 6.86       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 626         |\n",
            "|    ep_rew_mean          | 298         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 168         |\n",
            "|    iterations           | 46          |\n",
            "|    time_elapsed         | 559         |\n",
            "|    total_timesteps      | 94208       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.062563315 |\n",
            "|    clip_fraction        | 0.449       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | 0.77        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.381       |\n",
            "|    n_updates            | 450         |\n",
            "|    policy_gradient_loss | -0.0328     |\n",
            "|    value_loss           | 8.97        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 632        |\n",
            "|    ep_rew_mean          | 300        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 168        |\n",
            "|    iterations           | 47         |\n",
            "|    time_elapsed         | 571        |\n",
            "|    total_timesteps      | 96256      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07129317 |\n",
            "|    clip_fraction        | 0.475      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.33      |\n",
            "|    explained_variance   | 0.771      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.05       |\n",
            "|    n_updates            | 460        |\n",
            "|    policy_gradient_loss | -0.0334    |\n",
            "|    value_loss           | 8.21       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 632         |\n",
            "|    ep_rew_mean          | 300         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 168         |\n",
            "|    iterations           | 48          |\n",
            "|    time_elapsed         | 583         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.069151424 |\n",
            "|    clip_fraction        | 0.477       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.38       |\n",
            "|    explained_variance   | 0.782       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.384       |\n",
            "|    n_updates            | 470         |\n",
            "|    policy_gradient_loss | -0.0343     |\n",
            "|    value_loss           | 7.78        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 628        |\n",
            "|    ep_rew_mean          | 298        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 168        |\n",
            "|    iterations           | 49         |\n",
            "|    time_elapsed         | 595        |\n",
            "|    total_timesteps      | 100352     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06514385 |\n",
            "|    clip_fraction        | 0.462      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.4       |\n",
            "|    explained_variance   | 0.693      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.319      |\n",
            "|    n_updates            | 480        |\n",
            "|    policy_gradient_loss | -0.0385    |\n",
            "|    value_loss           | 7.89       |\n",
            "----------------------------------------\n",
            "\n",
            "=== TRAINING A2C ===\n",
            "Using cuda device\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 206      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | 0.288    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 0.0124   |\n",
            "|    value_loss         | 6.95e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 630      |\n",
            "|    ep_rew_mean        | 315      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | 0.399    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -0.0201  |\n",
            "|    value_loss         | 0.00013  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 556      |\n",
            "|    ep_rew_mean        | 252      |\n",
            "| time/                 |          |\n",
            "|    fps                | 218      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | -0.257   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -0.00311 |\n",
            "|    value_loss         | 3.67e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 594      |\n",
            "|    ep_rew_mean        | 266      |\n",
            "| time/                 |          |\n",
            "|    fps                | 219      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | -1.98    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | -0.074   |\n",
            "|    value_loss         | 0.00157  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 581      |\n",
            "|    ep_rew_mean        | 273      |\n",
            "| time/                 |          |\n",
            "|    fps                | 210      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -2.86    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | -0.0399  |\n",
            "|    value_loss         | 0.000846 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 578      |\n",
            "|    ep_rew_mean        | 269      |\n",
            "| time/                 |          |\n",
            "|    fps                | 212      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | -4.4     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 0.0147   |\n",
            "|    value_loss         | 0.000221 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 578      |\n",
            "|    ep_rew_mean        | 269      |\n",
            "| time/                 |          |\n",
            "|    fps                | 214      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | -1.16    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | -0.00767 |\n",
            "|    value_loss         | 3.48e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 600      |\n",
            "|    ep_rew_mean        | 273      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -0.232   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | -0.0104  |\n",
            "|    value_loss         | 5.9e-05  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 593      |\n",
            "|    ep_rew_mean        | 273      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 20       |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -2.62    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | -0.024   |\n",
            "|    value_loss         | 0.000202 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 591      |\n",
            "|    ep_rew_mean        | 268      |\n",
            "| time/                 |          |\n",
            "|    fps                | 212      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 23       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | 0.192    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | -0.014   |\n",
            "|    value_loss         | 6.9e-05  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 592      |\n",
            "|    ep_rew_mean        | 268      |\n",
            "| time/                 |          |\n",
            "|    fps                | 213      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 25       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | 0.00528  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 32.5     |\n",
            "|    value_loss         | 340      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 590      |\n",
            "|    ep_rew_mean        | 262      |\n",
            "| time/                 |          |\n",
            "|    fps                | 214      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | -5.47    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | 0.00757  |\n",
            "|    value_loss         | 0.000125 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 590      |\n",
            "|    ep_rew_mean        | 262      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 30       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | -1.61    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | -0.0371  |\n",
            "|    value_loss         | 0.000419 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 595      |\n",
            "|    ep_rew_mean        | 273      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 32       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | 0.0653   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | 0.0236   |\n",
            "|    value_loss         | 0.000179 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 588      |\n",
            "|    ep_rew_mean        | 270      |\n",
            "| time/                 |          |\n",
            "|    fps                | 214      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 34       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -16.6    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | -0.0614  |\n",
            "|    value_loss         | 0.00157  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 590      |\n",
            "|    ep_rew_mean        | 265      |\n",
            "| time/                 |          |\n",
            "|    fps                | 214      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 37       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | -0.437   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | -0.0205  |\n",
            "|    value_loss         | 0.000127 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 596      |\n",
            "|    ep_rew_mean        | 262      |\n",
            "| time/                 |          |\n",
            "|    fps                | 214      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 39       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.91    |\n",
            "|    explained_variance | -2.21    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | -0.0566  |\n",
            "|    value_loss         | 0.00109  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 599      |\n",
            "|    ep_rew_mean        | 267      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 41       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | 0.309    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | -0.27    |\n",
            "|    value_loss         | 0.0442   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 587      |\n",
            "|    ep_rew_mean        | 262      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 43       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.87    |\n",
            "|    explained_variance | -8.55    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | -0.0906  |\n",
            "|    value_loss         | 0.00214  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 584      |\n",
            "|    ep_rew_mean        | 263      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 46       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.88    |\n",
            "|    explained_variance | -0.264   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | -0.0233  |\n",
            "|    value_loss         | 0.000162 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 580      |\n",
            "|    ep_rew_mean        | 267      |\n",
            "| time/                 |          |\n",
            "|    fps                | 214      |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 48       |\n",
            "|    total_timesteps    | 10500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.91    |\n",
            "|    explained_variance | 0.000849 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | 16.5     |\n",
            "|    value_loss         | 174      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 580      |\n",
            "|    ep_rew_mean        | 267      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 51       |\n",
            "|    total_timesteps    | 11000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.9     |\n",
            "|    explained_variance | -14.8    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | -0.0924  |\n",
            "|    value_loss         | 0.00249  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 584      |\n",
            "|    ep_rew_mean        | 272      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 53       |\n",
            "|    total_timesteps    | 11500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.91    |\n",
            "|    explained_variance | -2.88    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | -0.0185  |\n",
            "|    value_loss         | 0.000162 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 584      |\n",
            "|    ep_rew_mean        | 271      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 2400     |\n",
            "|    time_elapsed       | 55       |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.9     |\n",
            "|    explained_variance | -1.06    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | -0.00807 |\n",
            "|    value_loss         | 5.44e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 585      |\n",
            "|    ep_rew_mean        | 271      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 57       |\n",
            "|    total_timesteps    | 12500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.86    |\n",
            "|    explained_variance | -4.61    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | -0.0796  |\n",
            "|    value_loss         | 0.00236  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 586      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 2600     |\n",
            "|    time_elapsed       | 60       |\n",
            "|    total_timesteps    | 13000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.91    |\n",
            "|    explained_variance | 0.394    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2599     |\n",
            "|    policy_loss        | 0.0144   |\n",
            "|    value_loss         | 9.49e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 586      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 2700     |\n",
            "|    time_elapsed       | 62       |\n",
            "|    total_timesteps    | 13500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | -0.233   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2699     |\n",
            "|    policy_loss        | 0.014    |\n",
            "|    value_loss         | 0.000111 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 587      |\n",
            "|    ep_rew_mean        | 281      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 2800     |\n",
            "|    time_elapsed       | 64       |\n",
            "|    total_timesteps    | 14000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | -2.2     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2799     |\n",
            "|    policy_loss        | -0.00443 |\n",
            "|    value_loss         | 7.94e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 584      |\n",
            "|    ep_rew_mean        | 277      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 2900     |\n",
            "|    time_elapsed       | 67       |\n",
            "|    total_timesteps    | 14500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -8.16    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2899     |\n",
            "|    policy_loss        | -0.0401  |\n",
            "|    value_loss         | 0.000647 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 582      |\n",
            "|    ep_rew_mean        | 277      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 3000     |\n",
            "|    time_elapsed       | 69       |\n",
            "|    total_timesteps    | 15000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | 0.114    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2999     |\n",
            "|    policy_loss        | 0.000287 |\n",
            "|    value_loss         | 1.68e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 580      |\n",
            "|    ep_rew_mean        | 277      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 3100     |\n",
            "|    time_elapsed       | 72       |\n",
            "|    total_timesteps    | 15500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | 0.592    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3099     |\n",
            "|    policy_loss        | 0.00855  |\n",
            "|    value_loss         | 3.93e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 577      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 3200     |\n",
            "|    time_elapsed       | 74       |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | 0.123    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3199     |\n",
            "|    policy_loss        | -0.0204  |\n",
            "|    value_loss         | 0.000121 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 574      |\n",
            "|    ep_rew_mean        | 274      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 76       |\n",
            "|    total_timesteps    | 16500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -0.6     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | -0.00702 |\n",
            "|    value_loss         | 6.37e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 576      |\n",
            "|    ep_rew_mean        | 278      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 3400     |\n",
            "|    time_elapsed       | 78       |\n",
            "|    total_timesteps    | 17000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -1.01    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3399     |\n",
            "|    policy_loss        | -0.0396  |\n",
            "|    value_loss         | 0.000498 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 578      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 80       |\n",
            "|    total_timesteps    | 17500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | -0.543   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | -0.0108  |\n",
            "|    value_loss         | 4.87e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 579      |\n",
            "|    ep_rew_mean        | 274      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 3600     |\n",
            "|    time_elapsed       | 83       |\n",
            "|    total_timesteps    | 18000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | 0.0519   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3599     |\n",
            "|    policy_loss        | -0.0117  |\n",
            "|    value_loss         | 5.72e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 574      |\n",
            "|    ep_rew_mean        | 272      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 3700     |\n",
            "|    time_elapsed       | 85       |\n",
            "|    total_timesteps    | 18500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | -48.9    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3699     |\n",
            "|    policy_loss        | -0.0408  |\n",
            "|    value_loss         | 0.000866 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 569      |\n",
            "|    ep_rew_mean        | 269      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 3800     |\n",
            "|    time_elapsed       | 88       |\n",
            "|    total_timesteps    | 19000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.91    |\n",
            "|    explained_variance | -18.5    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3799     |\n",
            "|    policy_loss        | -0.0395  |\n",
            "|    value_loss         | 0.00107  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 569      |\n",
            "|    ep_rew_mean        | 269      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 3900     |\n",
            "|    time_elapsed       | 90       |\n",
            "|    total_timesteps    | 19500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | 0.00302  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3899     |\n",
            "|    policy_loss        | 9.19     |\n",
            "|    value_loss         | 87.7     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 575      |\n",
            "|    ep_rew_mean        | 272      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 4000     |\n",
            "|    time_elapsed       | 92       |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -0.0244  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3999     |\n",
            "|    policy_loss        | -0.0429  |\n",
            "|    value_loss         | 0.000506 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 576      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 4100     |\n",
            "|    time_elapsed       | 94       |\n",
            "|    total_timesteps    | 20500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | 0.471    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4099     |\n",
            "|    policy_loss        | -0.00299 |\n",
            "|    value_loss         | 1.48e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 577      |\n",
            "|    ep_rew_mean        | 277      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 4200     |\n",
            "|    time_elapsed       | 97       |\n",
            "|    total_timesteps    | 21000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | 0.00279  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4199     |\n",
            "|    policy_loss        | 23       |\n",
            "|    value_loss         | 258      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 576      |\n",
            "|    ep_rew_mean        | 278      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 4300     |\n",
            "|    time_elapsed       | 99       |\n",
            "|    total_timesteps    | 21500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -0.106   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4299     |\n",
            "|    policy_loss        | 0.0296   |\n",
            "|    value_loss         | 0.000296 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 574      |\n",
            "|    ep_rew_mean        | 279      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 4400     |\n",
            "|    time_elapsed       | 101      |\n",
            "|    total_timesteps    | 22000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -12.4    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4399     |\n",
            "|    policy_loss        | -0.00923 |\n",
            "|    value_loss         | 0.000425 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 574      |\n",
            "|    ep_rew_mean        | 277      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 4500     |\n",
            "|    time_elapsed       | 104      |\n",
            "|    total_timesteps    | 22500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.87    |\n",
            "|    explained_variance | -3.66    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4499     |\n",
            "|    policy_loss        | -0.118   |\n",
            "|    value_loss         | 0.00449  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 574      |\n",
            "|    ep_rew_mean        | 277      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 4600     |\n",
            "|    time_elapsed       | 106      |\n",
            "|    total_timesteps    | 23000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | -1.42    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4599     |\n",
            "|    policy_loss        | -0.055   |\n",
            "|    value_loss         | 0.00075  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 572      |\n",
            "|    ep_rew_mean        | 274      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 4700     |\n",
            "|    time_elapsed       | 109      |\n",
            "|    total_timesteps    | 23500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | 0.369    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4699     |\n",
            "|    policy_loss        | -0.0103  |\n",
            "|    value_loss         | 4.36e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 567      |\n",
            "|    ep_rew_mean        | 271      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 4800     |\n",
            "|    time_elapsed       | 111      |\n",
            "|    total_timesteps    | 24000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | -2.3     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4799     |\n",
            "|    policy_loss        | -0.0556  |\n",
            "|    value_loss         | 0.000805 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 566      |\n",
            "|    ep_rew_mean        | 272      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 4900     |\n",
            "|    time_elapsed       | 113      |\n",
            "|    total_timesteps    | 24500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -1.23    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4899     |\n",
            "|    policy_loss        | -0.0354  |\n",
            "|    value_loss         | 0.000385 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 566      |\n",
            "|    ep_rew_mean        | 270      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 5000     |\n",
            "|    time_elapsed       | 115      |\n",
            "|    total_timesteps    | 25000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | 0.000599 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4999     |\n",
            "|    policy_loss        | 6.62     |\n",
            "|    value_loss         | 88.1     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 564      |\n",
            "|    ep_rew_mean        | 267      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 5100     |\n",
            "|    time_elapsed       | 118      |\n",
            "|    total_timesteps    | 25500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.9     |\n",
            "|    explained_variance | 0.409    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5099     |\n",
            "|    policy_loss        | -0.02    |\n",
            "|    value_loss         | 0.000113 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 565      |\n",
            "|    ep_rew_mean        | 270      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 5200     |\n",
            "|    time_elapsed       | 120      |\n",
            "|    total_timesteps    | 26000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.82    |\n",
            "|    explained_variance | -2.97    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5199     |\n",
            "|    policy_loss        | 0.0432   |\n",
            "|    value_loss         | 0.00113  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 565      |\n",
            "|    ep_rew_mean        | 270      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 5300     |\n",
            "|    time_elapsed       | 123      |\n",
            "|    total_timesteps    | 26500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.91    |\n",
            "|    explained_variance | -0.564   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5299     |\n",
            "|    policy_loss        | -0.0134  |\n",
            "|    value_loss         | 0.000141 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 568      |\n",
            "|    ep_rew_mean        | 273      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 5400     |\n",
            "|    time_elapsed       | 125      |\n",
            "|    total_timesteps    | 27000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.9     |\n",
            "|    explained_variance | 0.012    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5399     |\n",
            "|    policy_loss        | 8.54     |\n",
            "|    value_loss         | 87.2     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 567      |\n",
            "|    ep_rew_mean        | 272      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 5500     |\n",
            "|    time_elapsed       | 127      |\n",
            "|    total_timesteps    | 27500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.89    |\n",
            "|    explained_variance | -3.48    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5499     |\n",
            "|    policy_loss        | -0.0812  |\n",
            "|    value_loss         | 0.00175  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 568      |\n",
            "|    ep_rew_mean        | 273      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 5600     |\n",
            "|    time_elapsed       | 129      |\n",
            "|    total_timesteps    | 28000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | -0.24    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5599     |\n",
            "|    policy_loss        | -0.016   |\n",
            "|    value_loss         | 0.000107 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 570      |\n",
            "|    ep_rew_mean        | 273      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 5700     |\n",
            "|    time_elapsed       | 132      |\n",
            "|    total_timesteps    | 28500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.9     |\n",
            "|    explained_variance | 0.00377  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5699     |\n",
            "|    policy_loss        | 20.7     |\n",
            "|    value_loss         | 258      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 568      |\n",
            "|    ep_rew_mean        | 272      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 5800     |\n",
            "|    time_elapsed       | 134      |\n",
            "|    total_timesteps    | 29000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.91    |\n",
            "|    explained_variance | 0.743    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5799     |\n",
            "|    policy_loss        | -0.209   |\n",
            "|    value_loss         | 0.0253   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 567      |\n",
            "|    ep_rew_mean        | 272      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 5900     |\n",
            "|    time_elapsed       | 136      |\n",
            "|    total_timesteps    | 29500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.91    |\n",
            "|    explained_variance | 0.791    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5899     |\n",
            "|    policy_loss        | -0.432   |\n",
            "|    value_loss         | 0.0591   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 567      |\n",
            "|    ep_rew_mean        | 272      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 6000     |\n",
            "|    time_elapsed       | 139      |\n",
            "|    total_timesteps    | 30000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | -1.16    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5999     |\n",
            "|    policy_loss        | -0.0139  |\n",
            "|    value_loss         | 6.18e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 569      |\n",
            "|    ep_rew_mean        | 271      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 6100     |\n",
            "|    time_elapsed       | 141      |\n",
            "|    total_timesteps    | 30500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | 0.477    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6099     |\n",
            "|    policy_loss        | 0.00556  |\n",
            "|    value_loss         | 1.76e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 567      |\n",
            "|    ep_rew_mean        | 271      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 6200     |\n",
            "|    time_elapsed       | 143      |\n",
            "|    total_timesteps    | 31000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -17.8    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6199     |\n",
            "|    policy_loss        | -0.0541  |\n",
            "|    value_loss         | 0.00116  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 569      |\n",
            "|    ep_rew_mean        | 271      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 6300     |\n",
            "|    time_elapsed       | 146      |\n",
            "|    total_timesteps    | 31500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -3.04    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6299     |\n",
            "|    policy_loss        | -0.0422  |\n",
            "|    value_loss         | 0.000512 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 272      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 6400     |\n",
            "|    time_elapsed       | 148      |\n",
            "|    total_timesteps    | 32000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.9     |\n",
            "|    explained_variance | -13.9    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6399     |\n",
            "|    policy_loss        | 0.0337   |\n",
            "|    value_loss         | 0.00134  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 568      |\n",
            "|    ep_rew_mean        | 272      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 6500     |\n",
            "|    time_elapsed       | 150      |\n",
            "|    total_timesteps    | 32500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.88    |\n",
            "|    explained_variance | 0.00835  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6499     |\n",
            "|    policy_loss        | 18.9     |\n",
            "|    value_loss         | 174      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 568      |\n",
            "|    ep_rew_mean        | 273      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 6600     |\n",
            "|    time_elapsed       | 152      |\n",
            "|    total_timesteps    | 33000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.89    |\n",
            "|    explained_variance | -3.56    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6599     |\n",
            "|    policy_loss        | -0.0208  |\n",
            "|    value_loss         | 0.000414 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 568      |\n",
            "|    ep_rew_mean        | 273      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 6700     |\n",
            "|    time_elapsed       | 155      |\n",
            "|    total_timesteps    | 33500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | 0.00142  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6699     |\n",
            "|    policy_loss        | 31.8     |\n",
            "|    value_loss         | 342      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 569      |\n",
            "|    ep_rew_mean        | 272      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 6800     |\n",
            "|    time_elapsed       | 157      |\n",
            "|    total_timesteps    | 34000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -19.5    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6799     |\n",
            "|    policy_loss        | -0.0644  |\n",
            "|    value_loss         | 0.0015   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 569      |\n",
            "|    ep_rew_mean        | 271      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 6900     |\n",
            "|    time_elapsed       | 160      |\n",
            "|    total_timesteps    | 34500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -11.8    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6899     |\n",
            "|    policy_loss        | 0.0557   |\n",
            "|    value_loss         | 0.00135  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 570      |\n",
            "|    ep_rew_mean        | 273      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 7000     |\n",
            "|    time_elapsed       | 162      |\n",
            "|    total_timesteps    | 35000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -7.55    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6999     |\n",
            "|    policy_loss        | 0.0562   |\n",
            "|    value_loss         | 0.00122  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 567      |\n",
            "|    ep_rew_mean        | 272      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 7100     |\n",
            "|    time_elapsed       | 164      |\n",
            "|    total_timesteps    | 35500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7099     |\n",
            "|    policy_loss        | -0.0227  |\n",
            "|    value_loss         | 0.000195 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 564      |\n",
            "|    ep_rew_mean        | 271      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 7200     |\n",
            "|    time_elapsed       | 166      |\n",
            "|    total_timesteps    | 36000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7199     |\n",
            "|    policy_loss        | -0.00959 |\n",
            "|    value_loss         | 2.91e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 567      |\n",
            "|    ep_rew_mean        | 271      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 7300     |\n",
            "|    time_elapsed       | 169      |\n",
            "|    total_timesteps    | 36500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | -4.4     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7299     |\n",
            "|    policy_loss        | -0.0149  |\n",
            "|    value_loss         | 0.000355 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 567      |\n",
            "|    ep_rew_mean        | 270      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 7400     |\n",
            "|    time_elapsed       | 171      |\n",
            "|    total_timesteps    | 37000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.9     |\n",
            "|    explained_variance | 0.00974  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7399     |\n",
            "|    policy_loss        | 16.6     |\n",
            "|    value_loss         | 172      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 568      |\n",
            "|    ep_rew_mean        | 271      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 7500     |\n",
            "|    time_elapsed       | 173      |\n",
            "|    total_timesteps    | 37500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | -2.7     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7499     |\n",
            "|    policy_loss        | 0.154    |\n",
            "|    value_loss         | 0.00684  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 564      |\n",
            "|    ep_rew_mean        | 270      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 7600     |\n",
            "|    time_elapsed       | 176      |\n",
            "|    total_timesteps    | 38000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -10.9    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7599     |\n",
            "|    policy_loss        | -0.0534  |\n",
            "|    value_loss         | 0.00108  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 564      |\n",
            "|    ep_rew_mean        | 270      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 7700     |\n",
            "|    time_elapsed       | 178      |\n",
            "|    total_timesteps    | 38500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | -2.11    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7699     |\n",
            "|    policy_loss        | -0.0676  |\n",
            "|    value_loss         | 0.0013   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 564      |\n",
            "|    ep_rew_mean        | 269      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 7800     |\n",
            "|    time_elapsed       | 181      |\n",
            "|    total_timesteps    | 39000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | 0.00121  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7799     |\n",
            "|    policy_loss        | 30.3     |\n",
            "|    value_loss         | 342      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 564      |\n",
            "|    ep_rew_mean        | 268      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 7900     |\n",
            "|    time_elapsed       | 183      |\n",
            "|    total_timesteps    | 39500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -0.0199  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7899     |\n",
            "|    policy_loss        | -0.00782 |\n",
            "|    value_loss         | 4.83e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 564      |\n",
            "|    ep_rew_mean        | 268      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 8000     |\n",
            "|    time_elapsed       | 185      |\n",
            "|    total_timesteps    | 40000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | -0.00885 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7999     |\n",
            "|    policy_loss        | 16.6     |\n",
            "|    value_loss         | 176      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 564      |\n",
            "|    ep_rew_mean        | 267      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 8100     |\n",
            "|    time_elapsed       | 187      |\n",
            "|    total_timesteps    | 40500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | -37      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8099     |\n",
            "|    policy_loss        | 0.0576   |\n",
            "|    value_loss         | 0.00174  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 563      |\n",
            "|    ep_rew_mean        | 267      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 8200     |\n",
            "|    time_elapsed       | 189      |\n",
            "|    total_timesteps    | 41000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | 0.299    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8199     |\n",
            "|    policy_loss        | 0.00161  |\n",
            "|    value_loss         | 9.31e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 566      |\n",
            "|    ep_rew_mean        | 268      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 8300     |\n",
            "|    time_elapsed       | 192      |\n",
            "|    total_timesteps    | 41500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | 0.714    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8299     |\n",
            "|    policy_loss        | -0.0331  |\n",
            "|    value_loss         | 0.00029  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 568      |\n",
            "|    ep_rew_mean        | 268      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 8400     |\n",
            "|    time_elapsed       | 194      |\n",
            "|    total_timesteps    | 42000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -2.65    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8399     |\n",
            "|    policy_loss        | -0.0304  |\n",
            "|    value_loss         | 0.00036  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 568      |\n",
            "|    ep_rew_mean        | 268      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 8500     |\n",
            "|    time_elapsed       | 197      |\n",
            "|    total_timesteps    | 42500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -1.4     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8499     |\n",
            "|    policy_loss        | 0.0412   |\n",
            "|    value_loss         | 0.000591 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 567      |\n",
            "|    ep_rew_mean        | 269      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 8600     |\n",
            "|    time_elapsed       | 199      |\n",
            "|    total_timesteps    | 43000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | -2.51    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8599     |\n",
            "|    policy_loss        | 0.018    |\n",
            "|    value_loss         | 0.000189 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 568      |\n",
            "|    ep_rew_mean        | 269      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 8700     |\n",
            "|    time_elapsed       | 201      |\n",
            "|    total_timesteps    | 43500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -15.2    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8699     |\n",
            "|    policy_loss        | -0.0636  |\n",
            "|    value_loss         | 0.00155  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 567      |\n",
            "|    ep_rew_mean        | 269      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 8800     |\n",
            "|    time_elapsed       | 203      |\n",
            "|    total_timesteps    | 44000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | -8.69    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8799     |\n",
            "|    policy_loss        | -0.0373  |\n",
            "|    value_loss         | 0.00056  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 568      |\n",
            "|    ep_rew_mean        | 269      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 8900     |\n",
            "|    time_elapsed       | 206      |\n",
            "|    total_timesteps    | 44500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -11.6    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8899     |\n",
            "|    policy_loss        | -0.105   |\n",
            "|    value_loss         | 0.00383  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 568      |\n",
            "|    ep_rew_mean        | 270      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 9000     |\n",
            "|    time_elapsed       | 208      |\n",
            "|    total_timesteps    | 45000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.86    |\n",
            "|    explained_variance | -0.804   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8999     |\n",
            "|    policy_loss        | -0.0739  |\n",
            "|    value_loss         | 0.00169  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 569      |\n",
            "|    ep_rew_mean        | 272      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 9100     |\n",
            "|    time_elapsed       | 210      |\n",
            "|    total_timesteps    | 45500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.88    |\n",
            "|    explained_variance | -0.465   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9099     |\n",
            "|    policy_loss        | -0.0667  |\n",
            "|    value_loss         | 0.00147  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 569      |\n",
            "|    ep_rew_mean        | 272      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 9200     |\n",
            "|    time_elapsed       | 213      |\n",
            "|    total_timesteps    | 46000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | -0.114   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9199     |\n",
            "|    policy_loss        | 0.0635   |\n",
            "|    value_loss         | 0.00133  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 568      |\n",
            "|    ep_rew_mean        | 273      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 9300     |\n",
            "|    time_elapsed       | 215      |\n",
            "|    total_timesteps    | 46500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | 0.0404   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9299     |\n",
            "|    policy_loss        | 0.0167   |\n",
            "|    value_loss         | 0.000129 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 570      |\n",
            "|    ep_rew_mean        | 274      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 9400     |\n",
            "|    time_elapsed       | 217      |\n",
            "|    total_timesteps    | 47000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.9     |\n",
            "|    explained_variance | -1.03    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9399     |\n",
            "|    policy_loss        | -0.0283  |\n",
            "|    value_loss         | 0.000366 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 9500     |\n",
            "|    time_elapsed       | 220      |\n",
            "|    total_timesteps    | 47500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | -0.0835  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9499     |\n",
            "|    policy_loss        | -0.0291  |\n",
            "|    value_loss         | 0.000364 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 9600     |\n",
            "|    time_elapsed       | 222      |\n",
            "|    total_timesteps    | 48000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.88    |\n",
            "|    explained_variance | 0.154    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9599     |\n",
            "|    policy_loss        | 36.7     |\n",
            "|    value_loss         | 420      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 569      |\n",
            "|    ep_rew_mean        | 275      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 9700     |\n",
            "|    time_elapsed       | 224      |\n",
            "|    total_timesteps    | 48500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.91    |\n",
            "|    explained_variance | 0.0963   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9699     |\n",
            "|    policy_loss        | 37.1     |\n",
            "|    value_loss         | 421      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 569      |\n",
            "|    ep_rew_mean        | 275      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 9800     |\n",
            "|    time_elapsed       | 226      |\n",
            "|    total_timesteps    | 49000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | -4.55    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9799     |\n",
            "|    policy_loss        | -0.0256  |\n",
            "|    value_loss         | 0.000431 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 9900     |\n",
            "|    time_elapsed       | 229      |\n",
            "|    total_timesteps    | 49500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -1.33    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9899     |\n",
            "|    policy_loss        | -0.0137  |\n",
            "|    value_loss         | 0.000146 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 572      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 10000    |\n",
            "|    time_elapsed       | 231      |\n",
            "|    total_timesteps    | 50000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -0.398   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9999     |\n",
            "|    policy_loss        | 0.0579   |\n",
            "|    value_loss         | 0.000923 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 569      |\n",
            "|    ep_rew_mean        | 275      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 10100    |\n",
            "|    time_elapsed       | 233      |\n",
            "|    total_timesteps    | 50500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -4.06    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10099    |\n",
            "|    policy_loss        | -0.0619  |\n",
            "|    value_loss         | 0.00129  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 570      |\n",
            "|    ep_rew_mean        | 275      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 10200    |\n",
            "|    time_elapsed       | 236      |\n",
            "|    total_timesteps    | 51000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -2.13    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10199    |\n",
            "|    policy_loss        | 0.0264   |\n",
            "|    value_loss         | 0.000342 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 10300    |\n",
            "|    time_elapsed       | 238      |\n",
            "|    total_timesteps    | 51500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | 0.0769   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10299    |\n",
            "|    policy_loss        | -0.0399  |\n",
            "|    value_loss         | 0.000443 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 275      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 10400    |\n",
            "|    time_elapsed       | 240      |\n",
            "|    total_timesteps    | 52000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.91    |\n",
            "|    explained_variance | 0.00279  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10399    |\n",
            "|    policy_loss        | 22.8     |\n",
            "|    value_loss         | 258      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 275      |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 10500    |\n",
            "|    time_elapsed       | 243      |\n",
            "|    total_timesteps    | 52500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.87    |\n",
            "|    explained_variance | 0.48     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10499    |\n",
            "|    policy_loss        | 0.0151   |\n",
            "|    value_loss         | 0.000213 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 10600    |\n",
            "|    time_elapsed       | 245      |\n",
            "|    total_timesteps    | 53000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | 0.709    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10599    |\n",
            "|    policy_loss        | -0.00799 |\n",
            "|    value_loss         | 2.74e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 10700    |\n",
            "|    time_elapsed       | 247      |\n",
            "|    total_timesteps    | 53500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | -2.15    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10699    |\n",
            "|    policy_loss        | 0.0419   |\n",
            "|    value_loss         | 0.000643 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 570      |\n",
            "|    ep_rew_mean        | 275      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 10800    |\n",
            "|    time_elapsed       | 249      |\n",
            "|    total_timesteps    | 54000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -0.0846  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10799    |\n",
            "|    policy_loss        | 0.00471  |\n",
            "|    value_loss         | 3.48e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 10900    |\n",
            "|    time_elapsed       | 251      |\n",
            "|    total_timesteps    | 54500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.91    |\n",
            "|    explained_variance | -4.38    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10899    |\n",
            "|    policy_loss        | 0.0275   |\n",
            "|    value_loss         | 0.000564 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 570      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 11000    |\n",
            "|    time_elapsed       | 254      |\n",
            "|    total_timesteps    | 55000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | 0.386    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10999    |\n",
            "|    policy_loss        | 0.0642   |\n",
            "|    value_loss         | 0.00116  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 570      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 11100    |\n",
            "|    time_elapsed       | 256      |\n",
            "|    total_timesteps    | 55500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | -1.28    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11099    |\n",
            "|    policy_loss        | -0.0502  |\n",
            "|    value_loss         | 0.000826 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 570      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 11200    |\n",
            "|    time_elapsed       | 258      |\n",
            "|    total_timesteps    | 56000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.9     |\n",
            "|    explained_variance | -18.7    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11199    |\n",
            "|    policy_loss        | 0.124    |\n",
            "|    value_loss         | 0.0074   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 570      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 11300    |\n",
            "|    time_elapsed       | 261      |\n",
            "|    total_timesteps    | 56500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -8.22    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11299    |\n",
            "|    policy_loss        | -0.0621  |\n",
            "|    value_loss         | 0.00145  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 277      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 11400    |\n",
            "|    time_elapsed       | 263      |\n",
            "|    total_timesteps    | 57000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | 0.0312   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11399    |\n",
            "|    policy_loss        | 0.0139   |\n",
            "|    value_loss         | 6.74e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 11500    |\n",
            "|    time_elapsed       | 266      |\n",
            "|    total_timesteps    | 57500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | -0.255   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11499    |\n",
            "|    policy_loss        | -0.00617 |\n",
            "|    value_loss         | 3.33e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 275      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 11600    |\n",
            "|    time_elapsed       | 268      |\n",
            "|    total_timesteps    | 58000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | 0.851    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11599    |\n",
            "|    policy_loss        | -0.0308  |\n",
            "|    value_loss         | 0.000267 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 572      |\n",
            "|    ep_rew_mean        | 275      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 11700    |\n",
            "|    time_elapsed       | 270      |\n",
            "|    total_timesteps    | 58500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -0.208   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11699    |\n",
            "|    policy_loss        | 39.2     |\n",
            "|    value_loss         | 413      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 570      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 11800    |\n",
            "|    time_elapsed       | 272      |\n",
            "|    total_timesteps    | 59000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | -0.00364 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11799    |\n",
            "|    policy_loss        | 14.8     |\n",
            "|    value_loss         | 175      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 570      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 11900    |\n",
            "|    time_elapsed       | 274      |\n",
            "|    total_timesteps    | 59500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -5.63    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11899    |\n",
            "|    policy_loss        | -0.0387  |\n",
            "|    value_loss         | 0.000756 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 572      |\n",
            "|    ep_rew_mean        | 277      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 12000    |\n",
            "|    time_elapsed       | 277      |\n",
            "|    total_timesteps    | 60000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -5.73    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11999    |\n",
            "|    policy_loss        | -0.00119 |\n",
            "|    value_loss         | 0.000366 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 572       |\n",
            "|    ep_rew_mean        | 277       |\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 12100     |\n",
            "|    time_elapsed       | 279       |\n",
            "|    total_timesteps    | 60500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.93     |\n",
            "|    explained_variance | -0.664    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 12099     |\n",
            "|    policy_loss        | -0.000472 |\n",
            "|    value_loss         | 6.44e-05  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 570      |\n",
            "|    ep_rew_mean        | 277      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 12200    |\n",
            "|    time_elapsed       | 282      |\n",
            "|    total_timesteps    | 61000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -2.65    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12199    |\n",
            "|    policy_loss        | 0.0349   |\n",
            "|    value_loss         | 0.000534 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 570      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 12300    |\n",
            "|    time_elapsed       | 284      |\n",
            "|    total_timesteps    | 61500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -15.2    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12299    |\n",
            "|    policy_loss        | -0.0871  |\n",
            "|    value_loss         | 0.0028   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 278      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 12400    |\n",
            "|    time_elapsed       | 286      |\n",
            "|    total_timesteps    | 62000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | 0.502    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12399    |\n",
            "|    policy_loss        | -0.0469  |\n",
            "|    value_loss         | 0.000537 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 278      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 12500    |\n",
            "|    time_elapsed       | 289      |\n",
            "|    total_timesteps    | 62500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.84    |\n",
            "|    explained_variance | -2.37    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12499    |\n",
            "|    policy_loss        | -0.0282  |\n",
            "|    value_loss         | 0.000598 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 278      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 12600    |\n",
            "|    time_elapsed       | 291      |\n",
            "|    total_timesteps    | 63000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | -1.14    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12599    |\n",
            "|    policy_loss        | -0.0439  |\n",
            "|    value_loss         | 0.000781 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 279      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 12700    |\n",
            "|    time_elapsed       | 293      |\n",
            "|    total_timesteps    | 63500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -1.69    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12699    |\n",
            "|    policy_loss        | -0.0523  |\n",
            "|    value_loss         | 0.000769 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 278      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 12800    |\n",
            "|    time_elapsed       | 295      |\n",
            "|    total_timesteps    | 64000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.94    |\n",
            "|    explained_variance | 0.0037   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12799    |\n",
            "|    policy_loss        | 0.0974   |\n",
            "|    value_loss         | 0.00248  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 572      |\n",
            "|    ep_rew_mean        | 279      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 12900    |\n",
            "|    time_elapsed       | 298      |\n",
            "|    total_timesteps    | 64500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | 0.0142   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12899    |\n",
            "|    policy_loss        | 33.5     |\n",
            "|    value_loss         | 338      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 573      |\n",
            "|    ep_rew_mean        | 280      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 13000    |\n",
            "|    time_elapsed       | 300      |\n",
            "|    total_timesteps    | 65000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.86    |\n",
            "|    explained_variance | -4.42    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12999    |\n",
            "|    policy_loss        | -0.0724  |\n",
            "|    value_loss         | 0.00157  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 573      |\n",
            "|    ep_rew_mean        | 280      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 13100    |\n",
            "|    time_elapsed       | 303      |\n",
            "|    total_timesteps    | 65500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | -0.0708  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13099    |\n",
            "|    policy_loss        | 41.5     |\n",
            "|    value_loss         | 421      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 570      |\n",
            "|    ep_rew_mean        | 280      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 13200    |\n",
            "|    time_elapsed       | 305      |\n",
            "|    total_timesteps    | 66000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.9     |\n",
            "|    explained_variance | 0.675    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13199    |\n",
            "|    policy_loss        | -0.238   |\n",
            "|    value_loss         | 0.0465   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 570      |\n",
            "|    ep_rew_mean        | 280      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 13300    |\n",
            "|    time_elapsed       | 307      |\n",
            "|    total_timesteps    | 66500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | -3.13    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13299    |\n",
            "|    policy_loss        | -0.0373  |\n",
            "|    value_loss         | 0.0006   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 573      |\n",
            "|    ep_rew_mean        | 281      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 13400    |\n",
            "|    time_elapsed       | 309      |\n",
            "|    total_timesteps    | 67000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | 0.0309   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13399    |\n",
            "|    policy_loss        | -0.0248  |\n",
            "|    value_loss         | 0.000198 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 281      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 13500    |\n",
            "|    time_elapsed       | 311      |\n",
            "|    total_timesteps    | 67500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -1.14    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13499    |\n",
            "|    policy_loss        | -0.0431  |\n",
            "|    value_loss         | 0.000592 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 280      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 13600    |\n",
            "|    time_elapsed       | 314      |\n",
            "|    total_timesteps    | 68000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | 5.43e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13599    |\n",
            "|    policy_loss        | 30.1     |\n",
            "|    value_loss         | 341      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 570      |\n",
            "|    ep_rew_mean        | 278      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 13700    |\n",
            "|    time_elapsed       | 316      |\n",
            "|    total_timesteps    | 68500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.9     |\n",
            "|    explained_variance | -22.6    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13699    |\n",
            "|    policy_loss        | -0.101   |\n",
            "|    value_loss         | 0.00376  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 569      |\n",
            "|    ep_rew_mean        | 278      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 13800    |\n",
            "|    time_elapsed       | 319      |\n",
            "|    total_timesteps    | 69000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | 0.558    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13799    |\n",
            "|    policy_loss        | -0.0171  |\n",
            "|    value_loss         | 0.000108 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 570      |\n",
            "|    ep_rew_mean        | 280      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 13900    |\n",
            "|    time_elapsed       | 321      |\n",
            "|    total_timesteps    | 69500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | -3       |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13899    |\n",
            "|    policy_loss        | 0.0378   |\n",
            "|    value_loss         | 0.000687 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 568      |\n",
            "|    ep_rew_mean        | 277      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 14000    |\n",
            "|    time_elapsed       | 323      |\n",
            "|    total_timesteps    | 70000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | -35.2    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13999    |\n",
            "|    policy_loss        | -0.0241  |\n",
            "|    value_loss         | 0.0022   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 568      |\n",
            "|    ep_rew_mean        | 277      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 14100    |\n",
            "|    time_elapsed       | 326      |\n",
            "|    total_timesteps    | 70500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.88    |\n",
            "|    explained_variance | 0.013    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14099    |\n",
            "|    policy_loss        | 25.4     |\n",
            "|    value_loss         | 256      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 569      |\n",
            "|    ep_rew_mean        | 277      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 14200    |\n",
            "|    time_elapsed       | 328      |\n",
            "|    total_timesteps    | 71000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.87    |\n",
            "|    explained_variance | -0.226   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14199    |\n",
            "|    policy_loss        | -0.0166  |\n",
            "|    value_loss         | 0.00016  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 569      |\n",
            "|    ep_rew_mean        | 277      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 14300    |\n",
            "|    time_elapsed       | 330      |\n",
            "|    total_timesteps    | 71500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.89    |\n",
            "|    explained_variance | 0.575    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14299    |\n",
            "|    policy_loss        | -0.0563  |\n",
            "|    value_loss         | 0.000915 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 569      |\n",
            "|    ep_rew_mean        | 277      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 14400    |\n",
            "|    time_elapsed       | 332      |\n",
            "|    total_timesteps    | 72000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.92    |\n",
            "|    explained_variance | -37.9    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14399    |\n",
            "|    policy_loss        | -0.0431  |\n",
            "|    value_loss         | 0.00092  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 569      |\n",
            "|    ep_rew_mean        | 276      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 14500    |\n",
            "|    time_elapsed       | 335      |\n",
            "|    total_timesteps    | 72500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.84    |\n",
            "|    explained_variance | -2.04    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14499    |\n",
            "|    policy_loss        | -0.0171  |\n",
            "|    value_loss         | 0.000324 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 571      |\n",
            "|    ep_rew_mean        | 277      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 14600    |\n",
            "|    time_elapsed       | 337      |\n",
            "|    total_timesteps    | 73000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.9     |\n",
            "|    explained_variance | -1.81    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14599    |\n",
            "|    policy_loss        | -0.0597  |\n",
            "|    value_loss         | 0.000893 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 572      |\n",
            "|    ep_rew_mean        | 278      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 14700    |\n",
            "|    time_elapsed       | 339      |\n",
            "|    total_timesteps    | 73500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.86    |\n",
            "|    explained_variance | -0.861   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14699    |\n",
            "|    policy_loss        | -0.00114 |\n",
            "|    value_loss         | 0.000185 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 572      |\n",
            "|    ep_rew_mean        | 278      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 14800    |\n",
            "|    time_elapsed       | 342      |\n",
            "|    total_timesteps    | 74000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.89    |\n",
            "|    explained_variance | -2.77    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14799    |\n",
            "|    policy_loss        | -0.0895  |\n",
            "|    value_loss         | 0.00234  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 574      |\n",
            "|    ep_rew_mean        | 278      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 14900    |\n",
            "|    time_elapsed       | 344      |\n",
            "|    total_timesteps    | 74500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.88    |\n",
            "|    explained_variance | -11.1    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14899    |\n",
            "|    policy_loss        | -0.0391  |\n",
            "|    value_loss         | 0.00169  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 573      |\n",
            "|    ep_rew_mean        | 279      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 15000    |\n",
            "|    time_elapsed       | 346      |\n",
            "|    total_timesteps    | 75000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.89    |\n",
            "|    explained_variance | -18.2    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14999    |\n",
            "|    policy_loss        | -0.0618  |\n",
            "|    value_loss         | 0.00146  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 573      |\n",
            "|    ep_rew_mean        | 279      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 15100    |\n",
            "|    time_elapsed       | 348      |\n",
            "|    total_timesteps    | 75500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.87    |\n",
            "|    explained_variance | -1.36    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15099    |\n",
            "|    policy_loss        | 0.0895   |\n",
            "|    value_loss         | 0.00201  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 577      |\n",
            "|    ep_rew_mean        | 282      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 15200    |\n",
            "|    time_elapsed       | 351      |\n",
            "|    total_timesteps    | 76000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.86    |\n",
            "|    explained_variance | -1.14    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15199    |\n",
            "|    policy_loss        | 0.0235   |\n",
            "|    value_loss         | 0.000339 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 580      |\n",
            "|    ep_rew_mean        | 284      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 15300    |\n",
            "|    time_elapsed       | 353      |\n",
            "|    total_timesteps    | 76500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.76    |\n",
            "|    explained_variance | -0.216   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15299    |\n",
            "|    policy_loss        | 0.0392   |\n",
            "|    value_loss         | 0.000916 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 580      |\n",
            "|    ep_rew_mean        | 284      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 15400    |\n",
            "|    time_elapsed       | 355      |\n",
            "|    total_timesteps    | 77000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.9     |\n",
            "|    explained_variance | -8.9     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15399    |\n",
            "|    policy_loss        | -0.0721  |\n",
            "|    value_loss         | 0.00176  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 583      |\n",
            "|    ep_rew_mean        | 286      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 15500    |\n",
            "|    time_elapsed       | 358      |\n",
            "|    total_timesteps    | 77500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.9     |\n",
            "|    explained_variance | -23.9    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15499    |\n",
            "|    policy_loss        | -0.0884  |\n",
            "|    value_loss         | 0.00273  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 581      |\n",
            "|    ep_rew_mean        | 285      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 15600    |\n",
            "|    time_elapsed       | 360      |\n",
            "|    total_timesteps    | 78000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.88    |\n",
            "|    explained_variance | -0.217   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15599    |\n",
            "|    policy_loss        | -0.0632  |\n",
            "|    value_loss         | 0.00114  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 580      |\n",
            "|    ep_rew_mean        | 284      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 15700    |\n",
            "|    time_elapsed       | 363      |\n",
            "|    total_timesteps    | 78500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.88    |\n",
            "|    explained_variance | 0.00013  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15699    |\n",
            "|    policy_loss        | 10.4     |\n",
            "|    value_loss         | 88       |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 580      |\n",
            "|    ep_rew_mean        | 284      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 15800    |\n",
            "|    time_elapsed       | 365      |\n",
            "|    total_timesteps    | 79000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.68    |\n",
            "|    explained_variance | -20.5    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15799    |\n",
            "|    policy_loss        | -0.155   |\n",
            "|    value_loss         | 0.00685  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 579      |\n",
            "|    ep_rew_mean        | 283      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 15900    |\n",
            "|    time_elapsed       | 367      |\n",
            "|    total_timesteps    | 79500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.74    |\n",
            "|    explained_variance | 0.712    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15899    |\n",
            "|    policy_loss        | -0.012   |\n",
            "|    value_loss         | 5.12e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 578      |\n",
            "|    ep_rew_mean        | 282      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 16000    |\n",
            "|    time_elapsed       | 369      |\n",
            "|    total_timesteps    | 80000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.45    |\n",
            "|    explained_variance | -1.35    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15999    |\n",
            "|    policy_loss        | -0.00625 |\n",
            "|    value_loss         | 7.43e-05 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 579       |\n",
            "|    ep_rew_mean        | 284       |\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 16100     |\n",
            "|    time_elapsed       | 371       |\n",
            "|    total_timesteps    | 80500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.377    |\n",
            "|    explained_variance | -7.96     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16099     |\n",
            "|    policy_loss        | -0.000726 |\n",
            "|    value_loss         | 0.000484  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 578       |\n",
            "|    ep_rew_mean        | 284       |\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 16200     |\n",
            "|    time_elapsed       | 374       |\n",
            "|    total_timesteps    | 81000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.213    |\n",
            "|    explained_variance | -1.35     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16199     |\n",
            "|    policy_loss        | -0.000867 |\n",
            "|    value_loss         | 0.000679  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 579      |\n",
            "|    ep_rew_mean        | 286      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 16300    |\n",
            "|    time_elapsed       | 376      |\n",
            "|    total_timesteps    | 81500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.568   |\n",
            "|    explained_variance | -5.47    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16299    |\n",
            "|    policy_loss        | -0.0105  |\n",
            "|    value_loss         | 0.00072  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 580      |\n",
            "|    ep_rew_mean        | 287      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 16400    |\n",
            "|    time_elapsed       | 379      |\n",
            "|    total_timesteps    | 82000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.194   |\n",
            "|    explained_variance | -2.92    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16399    |\n",
            "|    policy_loss        | -0.00131 |\n",
            "|    value_loss         | 0.00232  |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 580       |\n",
            "|    ep_rew_mean        | 289       |\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 16500     |\n",
            "|    time_elapsed       | 381       |\n",
            "|    total_timesteps    | 82500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0667   |\n",
            "|    explained_variance | 0.114     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16499     |\n",
            "|    policy_loss        | -0.000259 |\n",
            "|    value_loss         | 0.000779  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 581      |\n",
            "|    ep_rew_mean        | 290      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 16600    |\n",
            "|    time_elapsed       | 383      |\n",
            "|    total_timesteps    | 83000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.027   |\n",
            "|    explained_variance | 0.209    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16599    |\n",
            "|    policy_loss        | 0.000234 |\n",
            "|    value_loss         | 0.00514  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 581      |\n",
            "|    ep_rew_mean        | 293      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 16700    |\n",
            "|    time_elapsed       | 386      |\n",
            "|    total_timesteps    | 83500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | 0.812    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16699    |\n",
            "|    policy_loss        | -0.654   |\n",
            "|    value_loss         | 0.13     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 581       |\n",
            "|    ep_rew_mean        | 293       |\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 16800     |\n",
            "|    time_elapsed       | 388       |\n",
            "|    total_timesteps    | 84000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.79     |\n",
            "|    explained_variance | -23.7     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16799     |\n",
            "|    policy_loss        | -0.000732 |\n",
            "|    value_loss         | 0.00069   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 584       |\n",
            "|    ep_rew_mean        | 294       |\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 16900     |\n",
            "|    time_elapsed       | 390       |\n",
            "|    total_timesteps    | 84500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0031   |\n",
            "|    explained_variance | -28.2     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 16899     |\n",
            "|    policy_loss        | -3.59e-05 |\n",
            "|    value_loss         | 0.0513    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 584      |\n",
            "|    ep_rew_mean        | 294      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 17000    |\n",
            "|    time_elapsed       | 392      |\n",
            "|    total_timesteps    | 85000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.11    |\n",
            "|    explained_variance | 0.00259  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16999    |\n",
            "|    policy_loss        | 28.2     |\n",
            "|    value_loss         | 259      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 583      |\n",
            "|    ep_rew_mean        | 296      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 17100    |\n",
            "|    time_elapsed       | 395      |\n",
            "|    total_timesteps    | 85500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.144   |\n",
            "|    explained_variance | -1.38    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17099    |\n",
            "|    policy_loss        | -0.00102 |\n",
            "|    value_loss         | 0.00255  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 584      |\n",
            "|    ep_rew_mean        | 297      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 17200    |\n",
            "|    time_elapsed       | 397      |\n",
            "|    total_timesteps    | 86000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0724  |\n",
            "|    explained_variance | -2.82    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17199    |\n",
            "|    policy_loss        | 0.00669  |\n",
            "|    value_loss         | 0.00307  |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 583       |\n",
            "|    ep_rew_mean        | 299       |\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 17300     |\n",
            "|    time_elapsed       | 399       |\n",
            "|    total_timesteps    | 86500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00753  |\n",
            "|    explained_variance | 0.415     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17299     |\n",
            "|    policy_loss        | -5.55e-06 |\n",
            "|    value_loss         | 0.000666  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 583      |\n",
            "|    ep_rew_mean        | 300      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 17400    |\n",
            "|    time_elapsed       | 402      |\n",
            "|    total_timesteps    | 87000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0249  |\n",
            "|    explained_variance | -17.2    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17399    |\n",
            "|    policy_loss        | 0.000583 |\n",
            "|    value_loss         | 0.0382   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 585       |\n",
            "|    ep_rew_mean        | 304       |\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 17500     |\n",
            "|    time_elapsed       | 404       |\n",
            "|    total_timesteps    | 87500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000522 |\n",
            "|    explained_variance | 0.0684    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17499     |\n",
            "|    policy_loss        | 3.59e-05  |\n",
            "|    value_loss         | 80.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 584       |\n",
            "|    ep_rew_mean        | 303       |\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 17600     |\n",
            "|    time_elapsed       | 406       |\n",
            "|    total_timesteps    | 88000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.58e-05 |\n",
            "|    explained_variance | 0.0534    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17599     |\n",
            "|    policy_loss        | 5.8e-06   |\n",
            "|    value_loss         | 244       |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 584      |\n",
            "|    ep_rew_mean        | 303      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 17700    |\n",
            "|    time_elapsed       | 408      |\n",
            "|    total_timesteps    | 88500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.618   |\n",
            "|    explained_variance | -4.46    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17699    |\n",
            "|    policy_loss        | -0.00751 |\n",
            "|    value_loss         | 0.00404  |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 583       |\n",
            "|    ep_rew_mean        | 307       |\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 17800     |\n",
            "|    time_elapsed       | 411       |\n",
            "|    total_timesteps    | 89000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000439 |\n",
            "|    explained_variance | -0.479    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17799     |\n",
            "|    policy_loss        | 1.81e-06  |\n",
            "|    value_loss         | 0.00618   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 581       |\n",
            "|    ep_rew_mean        | 307       |\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 17900     |\n",
            "|    time_elapsed       | 413       |\n",
            "|    total_timesteps    | 89500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000332 |\n",
            "|    explained_variance | -1.27     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 17899     |\n",
            "|    policy_loss        | -5.86e-06 |\n",
            "|    value_loss         | 0.058     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 581      |\n",
            "|    ep_rew_mean        | 307      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 18000    |\n",
            "|    time_elapsed       | 416      |\n",
            "|    total_timesteps    | 90000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.93    |\n",
            "|    explained_variance | -1.79    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17999    |\n",
            "|    policy_loss        | 0.0573   |\n",
            "|    value_loss         | 0.00091  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 582      |\n",
            "|    ep_rew_mean        | 309      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 18100    |\n",
            "|    time_elapsed       | 418      |\n",
            "|    total_timesteps    | 90500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.37    |\n",
            "|    explained_variance | -0.334   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18099    |\n",
            "|    policy_loss        | -0.00937 |\n",
            "|    value_loss         | 0.000197 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 586       |\n",
            "|    ep_rew_mean        | 311       |\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 18200     |\n",
            "|    time_elapsed       | 420       |\n",
            "|    total_timesteps    | 91000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0448   |\n",
            "|    explained_variance | -4.51     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18199     |\n",
            "|    policy_loss        | -0.000285 |\n",
            "|    value_loss         | 0.00805   |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 586      |\n",
            "|    ep_rew_mean        | 311      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 18300    |\n",
            "|    time_elapsed       | 423      |\n",
            "|    total_timesteps    | 91500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.91    |\n",
            "|    explained_variance | 0.0135   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18299    |\n",
            "|    policy_loss        | 23.2     |\n",
            "|    value_loss         | 255      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 586      |\n",
            "|    ep_rew_mean        | 311      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 18400    |\n",
            "|    time_elapsed       | 425      |\n",
            "|    total_timesteps    | 92000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.8     |\n",
            "|    explained_variance | -0.159   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18399    |\n",
            "|    policy_loss        | 39.6     |\n",
            "|    value_loss         | 428      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 587      |\n",
            "|    ep_rew_mean        | 315      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 18500    |\n",
            "|    time_elapsed       | 427      |\n",
            "|    total_timesteps    | 92500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.19    |\n",
            "|    explained_variance | -7.03    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18499    |\n",
            "|    policy_loss        | -0.00112 |\n",
            "|    value_loss         | 0.00566  |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 587       |\n",
            "|    ep_rew_mean        | 317       |\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 18600     |\n",
            "|    time_elapsed       | 430       |\n",
            "|    total_timesteps    | 93000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -3.49e-06 |\n",
            "|    explained_variance | -18.2     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18599     |\n",
            "|    policy_loss        | -2.44e-08 |\n",
            "|    value_loss         | 0.849     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 587      |\n",
            "|    ep_rew_mean        | 317      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 18700    |\n",
            "|    time_elapsed       | 432      |\n",
            "|    total_timesteps    | 93500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.59    |\n",
            "|    explained_variance | 0.00991  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18699    |\n",
            "|    policy_loss        | 24.5     |\n",
            "|    value_loss         | 255      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 588      |\n",
            "|    ep_rew_mean        | 318      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 18800    |\n",
            "|    time_elapsed       | 435      |\n",
            "|    total_timesteps    | 94000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.71    |\n",
            "|    explained_variance | -41.8    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18799    |\n",
            "|    policy_loss        | -0.0706  |\n",
            "|    value_loss         | 0.00608  |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 590       |\n",
            "|    ep_rew_mean        | 319       |\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 18900     |\n",
            "|    time_elapsed       | 437       |\n",
            "|    total_timesteps    | 94500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.43e-06 |\n",
            "|    explained_variance | -3.1      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18899     |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.579     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 592       |\n",
            "|    ep_rew_mean        | 321       |\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 19000     |\n",
            "|    time_elapsed       | 439       |\n",
            "|    total_timesteps    | 95000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0018   |\n",
            "|    explained_variance | -3.69     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 18999     |\n",
            "|    policy_loss        | -1.91e-05 |\n",
            "|    value_loss         | 0.0317    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 590       |\n",
            "|    ep_rew_mean        | 320       |\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 19100     |\n",
            "|    time_elapsed       | 441       |\n",
            "|    total_timesteps    | 95500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.0302   |\n",
            "|    explained_variance | -2.87e+03 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19099     |\n",
            "|    policy_loss        | -0.00454  |\n",
            "|    value_loss         | 8.23      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 587       |\n",
            "|    ep_rew_mean        | 320       |\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 19200     |\n",
            "|    time_elapsed       | 444       |\n",
            "|    total_timesteps    | 96000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000258 |\n",
            "|    explained_variance | -0.593    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19199     |\n",
            "|    policy_loss        | 1.97e-06  |\n",
            "|    value_loss         | 0.0185    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 587      |\n",
            "|    ep_rew_mean        | 322      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 19300    |\n",
            "|    time_elapsed       | 446      |\n",
            "|    total_timesteps    | 96500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.2     |\n",
            "|    explained_variance | -97.7    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19299    |\n",
            "|    policy_loss        | -0.00225 |\n",
            "|    value_loss         | 0.00023  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 590      |\n",
            "|    ep_rew_mean        | 324      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 19400    |\n",
            "|    time_elapsed       | 449      |\n",
            "|    total_timesteps    | 97000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00229 |\n",
            "|    explained_variance | -16.3    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19399    |\n",
            "|    policy_loss        | 0.000123 |\n",
            "|    value_loss         | 0.315    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 591       |\n",
            "|    ep_rew_mean        | 325       |\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 19500     |\n",
            "|    time_elapsed       | 451       |\n",
            "|    total_timesteps    | 97500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.73e-06 |\n",
            "|    explained_variance | 0.593     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19499     |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.00429   |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 591      |\n",
            "|    ep_rew_mean        | 325      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 19600    |\n",
            "|    time_elapsed       | 453      |\n",
            "|    total_timesteps    | 98000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.85    |\n",
            "|    explained_variance | -8.26    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19599    |\n",
            "|    policy_loss        | -0.00986 |\n",
            "|    value_loss         | 0.00583  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 592      |\n",
            "|    ep_rew_mean        | 327      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 19700    |\n",
            "|    time_elapsed       | 455      |\n",
            "|    total_timesteps    | 98500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.636   |\n",
            "|    explained_variance | -1e+03   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19699    |\n",
            "|    policy_loss        | 0.00196  |\n",
            "|    value_loss         | 0.000206 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 593      |\n",
            "|    ep_rew_mean        | 329      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 19800    |\n",
            "|    time_elapsed       | 457      |\n",
            "|    total_timesteps    | 99000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00754 |\n",
            "|    explained_variance | -0.782   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19799    |\n",
            "|    policy_loss        | -0.00013 |\n",
            "|    value_loss         | 0.0271   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 593       |\n",
            "|    ep_rew_mean        | 330       |\n",
            "| time/                 |           |\n",
            "|    fps                | 216       |\n",
            "|    iterations         | 19900     |\n",
            "|    time_elapsed       | 460       |\n",
            "|    total_timesteps    | 99500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.27e-06 |\n",
            "|    explained_variance | -2.38     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 19899     |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.0306    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 594      |\n",
            "|    ep_rew_mean        | 332      |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 20000    |\n",
            "|    time_elapsed       | 462      |\n",
            "|    total_timesteps    | 100000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -3.2e-09 |\n",
            "|    explained_variance | -1.44    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19999    |\n",
            "|    policy_loss        | -0       |\n",
            "|    value_loss         | 0.126    |\n",
            "------------------------------------\n",
            "\n",
            "=== TRAINING REINFORCE (Discrete Only) ===\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (33600x3 and 210x128)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-640a7c2f0189>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n=== TRAINING REINFORCE (Discrete Only) ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0menv_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menvs_discrete\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain_reinforce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-30574c0f03cc>\u001b[0m in \u001b[0;36mtrain_reinforce\u001b[0;34m(env_id, num_episodes, lr, gamma)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mobs_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-30574c0f03cc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_reinforce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (33600x3 and 210x128)"
          ]
        }
      ]
    }
  ]
}